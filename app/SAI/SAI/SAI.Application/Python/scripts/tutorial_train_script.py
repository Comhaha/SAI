import os
import sys
import subprocess
import logging
import json
import platform
import re
import time
import threading
import zipfile
import glob
import io
from datetime import datetime

# í‘œì¤€ ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
try:
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
except Exception as e:
    # ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆê±°ë‚˜ ë‹«í˜€ìˆëŠ” ê²½ìš° ë¬´ì‹œ
    pass

# base_dirì„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
# 
base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
print(f"Base directory: {base_dir}")

# ë¡œê¹… ì„¤ì • - ì‹œê°„ í¬ë§· ë³€ê²½ ë° ìƒì„¸ ì •ë³´ í‘œì‹œ
logging.basicConfig(
    encoding='utf-8',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ì§„í–‰ ìƒí™© í‘œì‹œ í•¨ìˆ˜
def show_progress(message, start_time=None, progress=None):
    """ì§„í–‰ ìƒí™© ë° ê²½ê³¼ ì‹œê°„ í‘œì‹œ"""
    try:
        elapsed_str = ""
        if start_time:
            elapsed = time.time() - start_time
            minutes, seconds = divmod(elapsed, 60)
            elapsed_str = f"[{int(minutes):02d}:{int(seconds):02d}] "
            
        progress_str = ""
        if progress is not None:
            progress_str = f"[{progress:.1f}%] "
        
        full_message = f"{elapsed_str}{progress_str}{message}"
        logger.info(full_message)
        
        # C# ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‰½ê²Œ íŒŒì‹±í•  ìˆ˜ ìˆëŠ” íƒœê·¸ ì¶”ê°€
        if progress is not None:
            print(f"PROGRESS:{progress:.1f}:{message}", flush=True)
        else:
            print(f"PROGRESS::{message}", flush=True)
    except Exception as e:
        logger.error(f"show_progress ì˜¤ë¥˜: {e}")

# pip ì„¤ì¹˜ ì§„í–‰ë¥  ì¶”ì  í´ë˜ìŠ¤
class PipProgressTracker:
    def __init__(self, packages, start_time, total_steps=100):
        self.packages = packages
        self.start_time = start_time
        self.total_steps = total_steps
        self.current_step = 0
        self.found_packages = set()
        self.completed = False
        self.last_progress_time = time.time()
    
    def update_from_output(self, line):
        """pip ì¶œë ¥ì—ì„œ ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        for package in self.packages:
            if package in line.lower() and package not in self.found_packages:
                self.found_packages.add(package)
                self.current_step += (self.total_steps / len(self.packages)) * 0.5
                show_progress(f"íŒ¨í‚¤ì§€ {package} ì„¤ì¹˜ ì¤‘: {line}", self.start_time, self.current_step)
                return True
        
        if "collecting" in line.lower() or "downloading" in line.lower():
            self.current_step += 0.5
            self.current_step = min(self.current_step, self.total_steps * 0.7)  # ìµœëŒ€ 70%ê¹Œì§€ë§Œ
            show_progress(f"íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘: {line}", self.start_time, self.current_step)
            self.last_progress_time = time.time()
            return True
            
        if "installing collected packages" in line.lower():
            self.current_step = self.total_steps * 0.8
            show_progress(f"íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘: {line}", self.start_time, self.current_step)
            self.last_progress_time = time.time()
            return True
            
        if "successfully installed" in line.lower():
            self.current_step = self.total_steps
            self.completed = True
            show_progress(f"íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ: {line}", self.start_time, self.current_step)
            return True
        
        # ì¼ì • ì‹œê°„ ê²½ê³¼ì‹œ ì§„í–‰ ì¤‘ì„ì„ í‘œì‹œ
        if time.time() - self.last_progress_time > 5:
            show_progress("íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì§„í–‰ ì¤‘...", self.start_time, self.current_step)
            self.last_progress_time = time.time()
            return True
            
        return False

def install_packages_with_progress(packages, start_time):
    """íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì§„í–‰ë¥  í‘œì‹œ"""
    if not isinstance(packages, list):
        packages = [packages]
    
    # ì„¤ì¹˜ ì§„í–‰ ìƒí™© ì¶”ì ê¸° ìƒì„±
    tracker = PipProgressTracker(packages, start_time)
    
    # ì„¤ì¹˜ ëª…ë ¹ ì¤€ë¹„
    install_cmd = [
        sys.executable, "-m", "pip", "install", 
        *packages, 
        "--verbose"
    ]
    
    # ì‹¤ì‹œê°„ ì¶œë ¥ ìº¡ì²˜ë¥¼ ìœ„í•œ Popen ì‚¬ìš©
    process = subprocess.Popen(
        install_cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        universal_newlines=True,
        bufsize=1
    )
    
    # ì¶œë ¥ ì²˜ë¦¬
    for line in iter(process.stdout.readline, ''):
        tracker.update_from_output(line.strip())
    
    process.wait()
    
    # ì„¤ì¹˜ ì™„ë£Œ í™•ì¸
    if not tracker.completed:
        tracker.current_step = 100
        show_progress(f"{', '.join(packages)} ì„¤ì¹˜ ì™„ë£Œ", start_time, 100)
    
    return process.returncode == 0

def install_torch_cuda():
    """ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ CUDA ì§€ì› PyTorch ì„¤ì¹˜"""
    start_time = time.time()
    show_progress("CUDA ì§€ì› PyTorch ì„¤ì¹˜ ì¤€ë¹„ ì¤‘...", start_time, 0)
    
    # ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
    script_path = os.path.join(base_dir, "scripts", "install_pytorch_cuda.py")
    
    # ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    show_progress("ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ PyTorch ì„¤ì¹˜ ì‹¤í–‰ ì¤‘...", start_time, 20)
    subprocess.run([sys.executable, script_path])
    
    # ê²°ê³¼ í™•ì¸
    result_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "pytorch_install_result.txt")
    if os.path.exists(result_path):
        with open(result_path, "r") as f:
            result = f.read().strip()
        
        # ê²°ê³¼ íŒŒì¼ ì‚­ì œ
        try:
            os.remove(result_path)
        except:
            pass
        
        if result == "CUDA_SUCCESS":
            show_progress("PyTorch CUDA ì„¤ì¹˜ ì„±ê³µ!", start_time, 100)
            return True, "cuda"
        elif result == "GPU_NOT_DETECTED":
            show_progress("PyTorch ì„¤ì¹˜ëŠ” ì„±ê³µí–ˆìœ¼ë‚˜ GPUë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", start_time, 100)
            return False, "cpu"
        else:
            show_progress(f"PyTorch ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {result}", start_time, 100)
            return False, "cpu"
    else:
        show_progress("PyTorch ì„¤ì¹˜ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", start_time, 100)
        return False, "cpu"

def download_dataset_with_progress(start_time):
    """ì„œë²„ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì§„í–‰ë¥  í‘œì‹œ"""
    # ë°ì´í„°ì…‹ ì €ì¥ ê²½ë¡œ ì„¤ì •, ë®ì–´ì“°ê¸° 
    dataset_dir = os.path.join(base_dir, "dataset", "tutorial_dataset")
    os.makedirs(dataset_dir, exist_ok=True)
    show_progress(f"ë°ì´í„°ì…‹ ê¸°ë³¸ ê²½ë¡œ: {dataset_dir}", start_time, 70)

    # ZIP íŒŒì¼ ê²½ë¡œ ì •ì˜
    zip_path = os.path.join(dataset_dir, "tutorial_dataset.zip")
    
    # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
    if os.path.exists(zip_path):
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()
                total_files = len(file_list)
                show_progress(f"ì••ì¶• íŒŒì¼ ë‚´ {total_files}ê°œ íŒŒì¼ ë°œê²¬", start_time, 92)
                
                # ì••ì¶• í•´ì œ ì§„í–‰ë¥  í‘œì‹œ
                for i, file in enumerate(file_list):
                    zip_ref.extract(file, dataset_dir)  # tutorial_dataset í´ë”ì— ì••ì¶• í•´ì œ
                    if i % 50 == 0 or i == total_files - 1:  # 50ê°œ íŒŒì¼ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ íŒŒì¼ì—ì„œ ì§„í–‰ë¥  í‘œì‹œ
                        extract_progress = 92 + (i / total_files) * 8  # 92% ~ 100% ë²”ìœ„
                        show_progress(f"ì••ì¶• í•´ì œ ì¤‘: {i+1}/{total_files} íŒŒì¼", start_time, extract_progress)
            
            show_progress("ì••ì¶• í•´ì œ ì™„ë£Œ", start_time, 100)
            
            # ì„ì‹œ ZIP íŒŒì¼ ì‚­ì œ
            try:
                os.remove(zip_path)
                show_progress("ì„ì‹œ ZIP íŒŒì¼ ì‚­ì œ ì™„ë£Œ", start_time, 100)
            except:
                show_progress("ì„ì‹œ ZIP íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨", start_time, 100)
        except Exception as e:
            show_progress(f"ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì˜¤ë¥˜: {e}", start_time, 95)
    else:
        show_progress("ë‹¤ìš´ë¡œë“œëœ ZIP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", start_time, 95)
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ
    # 
    return type('obj', (), {'location': dataset_dir})

def find_yaml_file(dataset_dir, start_time):
    """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ì—ì„œ data.yaml íŒŒì¼ ì°¾ê¸°"""
    show_progress(f"ë°ì´í„° ê²½ë¡œ í™•ì¸: {dataset_dir}", start_time, 0)
    
    # ê¸°ë³¸ data.yaml ê²½ë¡œ
    yaml_path = os.path.join(dataset_dir, "data.yaml")
    
    # data.yaml íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if (os.path.exists(yaml_path)):
        show_progress(f"ë°ì´í„° íŒŒì¼ í™•ì¸ë¨: {yaml_path}", start_time, 100)
        return yaml_path
    
    # ê¸°ë³¸ ìœ„ì¹˜ì— ì—†ìœ¼ë©´ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ê²€ìƒ‰
    show_progress("ë°ì´í„° íŒŒì¼ì„ ê²€ìƒ‰ ì¤‘...", start_time, 50)
    
    for root, dirs, files in os.walk(dataset_dir):
        for file in files:
            if file == 'data.yaml':
                yaml_path = os.path.join(root, file)
                show_progress(f"ë°ì´í„° íŒŒì¼ ë°œê²¬: {yaml_path}", start_time, 100)
                return yaml_path
    
    # íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš°
    show_progress(f"data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {yaml_path}", start_time, 100)
    return yaml_path

def check_gpu():
    """GPU ìƒíƒœ í™•ì¸ ë° ì •ë³´ ë°˜í™˜"""
    start_time = time.time()
    show_progress("GPU í™•ì¸ ì¤‘...", start_time, 0)
    
    try:
        import torch
        show_progress("PyTorch GPU ê¸°ëŠ¥ í™•ì¸ ì¤‘...", start_time, 25)
        
        if torch.cuda.is_available():
            show_progress("CUDA ì§€ì› í™•ì¸ë¨", start_time, 50)
            gpu_count = torch.cuda.device_count()
            gpu_names = [torch.cuda.get_device_name(i) for i in range(gpu_count)]
            cuda_version = torch.version.cuda
            gpu_memory = []
            
            show_progress(f"GPU {gpu_count}ê°œ ê°ì§€ë¨", start_time, 75)
            
            for i in range(gpu_count):
                try:
                    props = torch.cuda.get_device_properties(i)
                    mem_gb = props.total_memory / (1024**3)
                    gpu_memory.append(round(mem_gb, 1))
                    show_progress(f"GPU {i}: {gpu_names[i]} ({gpu_memory[-1]} GB)", start_time, 80 + (i+1) * (20/gpu_count))
                except:
                    gpu_memory.append(None)
                    show_progress(f"GPU {i}: {gpu_names[i]} (ë©”ëª¨ë¦¬ ì •ë³´ ì—†ìŒ)", start_time, 80 + (i+1) * (20/gpu_count))
            
            show_progress(f"CUDA ë²„ì „: {cuda_version}", start_time, 100)
            
            return {
                "available": True,
                "count": gpu_count,
                "names": gpu_names,
                "cuda_version": cuda_version,
                "memory_gb": gpu_memory
            }
        else:
            show_progress("GPU ê°ì§€ ì•ˆë¨: CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.", start_time, 100)
            return {"available": False}
    except Exception as e:
        show_progress(f"GPU í™•ì¸ ì˜¤ë¥˜: {e}", start_time, 100)
        return {"available": False, "error": str(e)}    
    
def find_latest_results_dir():
    """ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ results ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
    base_runs_dir = os.path.join(base_dir, "runs", "detect")
    
    if not os.path.exists(base_runs_dir):
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(base_runs_dir, exist_ok=True)
        return os.path.join(base_dir, "runs", "detect", "train")
    
    # 'train'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  í´ë” ì°¾ê¸°
    train_dirs = [d for d in os.listdir(base_runs_dir) if d.startswith('train')]
    if not train_dirs:
        return os.path.join(base_dir, "runs", "detect", "train")
    
    # ìˆ«ì ì ‘ë¯¸ì‚¬ê°€ ìˆëŠ” ê²½ìš° ê°€ì¥ í° ìˆ«ì ì°¾ê¸°
    latest_dir = "train"
    max_num = 0
    for d in train_dirs:
        # train, train1, train2, ... í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ
        match = re.match(r'train(\d*)', d)
        if match:
            num_str = match.group(1)
            num = int(num_str) if num_str else 0
            if num > max_num:
                max_num = num
                latest_dir = d
    
    return os.path.join(base_dir, "runs", "detect", latest_dir)
    
def visualize_training_results(results_path, start_time):
    """í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ ì‹œê°í™”"""
    try:
        # ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
        if not os.path.exists(results_path):
            show_progress(f"ê²°ê³¼ ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_path}", start_time, 100)
            return False
        
        show_progress(f"í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ í™•ì¸: {results_path}", start_time, 100)
        
        # ì—¬ê¸°ì„œëŠ” íŒŒì¼ ê²½ë¡œë§Œ ë°˜í™˜ (ì‹¤ì œ í‘œì‹œëŠ” C# UIì—ì„œ ìˆ˜í–‰)
        return results_path
    except Exception as e:
        show_progress(f"ê²°ê³¼ ì‹œê°í™” ì˜¤ë¥˜: {e}", start_time, 100)
        return False    

def run_inference(model_path, image_path, start_time, conf_threshold=0.25, show=True):
    """ëª¨ë¸ì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ íƒì§€ ìˆ˜í–‰"""
    try:
        # ëª¨ë¸ ê²½ë¡œ ë° ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
        if not os.path.exists(model_path):
            show_progress(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}", start_time, 0)
            return None
        
        if not os.path.exists(image_path):
            show_progress(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}", start_time, 0)
            return None
        
        show_progress(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}", start_time, 10)
        from ultralytics import YOLO
        model = YOLO(model_path)
        
        show_progress(f"ì´ë¯¸ì§€ ì¶”ë¡  ì¤‘: {image_path}", start_time, 30)
        results = model.predict(source=image_path, save=False, show=False, conf=conf_threshold)
        
        if not results or len(results) == 0:
            show_progress("ì¶”ë¡  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤", start_time, 50)
            return None
        
        # ê²°ê³¼ ì²˜ë¦¬
        show_progress("ì¶”ë¡  ê²°ê³¼ ì²˜ë¦¬ ì¤‘...", start_time, 70)
        
        # ê²°ê³¼ ì‹œê°í™”
        result_img = results[0].plot()  # BGR í˜•ì‹
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        output_dir = base_dir  # Python í´ë” ì‚¬ìš©
        output_path = os.path.join(output_dir, "inference_result.jpg")
        import cv2
        cv2.imwrite(output_path, result_img)

        import matplotlib
        matplotlib.use("TkAgg")

        # âœ… matplotlib ì‹œê°í™” ì¶”ê°€
        import matplotlib.pyplot as plt
        result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
        plt.imshow(result_rgb)
        plt.axis("off")
        plt.title("YOLOv8 Prediction")
        plt.show()
        input("ğŸ” ì°½ì´ ë–´ë‚˜ìš”? ì•„ë¬´ í‚¤ë‚˜ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        
        # íƒì§€ ê²°ê³¼ ì¶”ì¶œ (JSONìœ¼ë¡œ ë°˜í™˜í•˜ê¸° ìœ„í•¨)
        detections = []
        if hasattr(results[0], 'boxes') and results[0].boxes is not None:
            for box in results[0].boxes:
                # ë°•ìŠ¤ ì¢Œí‘œ
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                
                # í´ë˜ìŠ¤ ë° ì‹ ë¢°ë„
                cls = int(box.cls[0].item())
                conf = float(box.conf[0].item())
                
                # í´ë˜ìŠ¤ ì´ë¦„
                cls_name = results[0].names[cls]
                
                detections.append({
                    "class": cls_name,
                    "confidence": conf,
                    "bbox": [x1, y1, x2, y2]
                })
        
        show_progress(f"ì¶”ë¡  ì™„ë£Œ: {len(detections)}ê°œ ê°ì²´ ê°ì§€ë¨", start_time, 100)
        
        return {
            "image_path": image_path,
            "result_image": output_path,
            "detections": detections
        }
        
    except Exception as e:
        show_progress(f"ì¶”ë¡  ì˜¤ë¥˜: {e}", start_time, 100)
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    total_start_time = time.time()
    current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    show_progress(f"AI ë¸”ë¡ ì½”ë”© íŠœí† ë¦¬ì–¼ ëª¨ë“œ ì‹¤í–‰ ì‹œì‘ - {current_date}", total_start_time, 0)
    
    # 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    package_start_time = time.time()
    show_progress("í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘... (1/7)", total_start_time, 0)

    # NumPy ë‹¤ìš´ê·¸ë ˆì´ë“œ
    show_progress("NumPy ë‹¤ìš´ê·¸ë ˆì´ë“œ ì¤‘...", package_start_time, 0)
    install_packages_with_progress("numpy==1.24.3", package_start_time)
        
    # ultralytics ì„¤ì¹˜
    show_progress("ultralytics íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...", package_start_time, 0)
    install_packages_with_progress("ultralytics", package_start_time)

    # OpenCV ì„¤ì¹˜ ì¶”ê°€
    show_progress("opencv-python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...", package_start_time, 0)
    install_packages_with_progress("opencv-python", package_start_time)
    
    pkg_elapsed = time.time() - package_start_time
    show_progress(f"íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {int(pkg_elapsed)}ì´ˆ)", total_start_time, 100)
   
    # 2. PyTorch ì„¤ì¹˜ í™•ì¸ ë° CUDA ì§€ì› í™•ì¸
    torch_start_time = time.time()
    show_progress("PyTorch í™•ì¸ ì¤‘... (2/7)", total_start_time, 0)

    # ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ PyTorch ì„¤ì¹˜
    cuda_available, device = install_torch_cuda()  # ì—¬ê¸°ì„œ ë°˜í™˜ ê°’ì„ ì˜¬ë°”ë¥´ê²Œ ë°›ì•„ì•¼ í•¨

    torch_elapsed = time.time() - torch_start_time
    show_progress(f"PyTorch í™•ì¸ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {int(torch_elapsed)}ì´ˆ)", total_start_time, 100)
    
    # 3. GPU ì •ë³´ í™•ì¸
    gpu_start_time = time.time()
    show_progress("GPU ì •ë³´ í™•ì¸ ì¤‘... (3/7)", total_start_time, 0)
    gpu_info = check_gpu()
    gpu_elapsed = time.time() - gpu_start_time
    show_progress(f"GPU ì •ë³´ í™•ì¸ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {int(gpu_elapsed)}ì´ˆ)", total_start_time, 100)
    
    # 4. YOLO ëª¨ë¸ ë¡œë“œ
    model_start_time = time.time()
    show_progress("YOLOv8 ëª¨ë¸ ë¡œë“œ ì¤‘... (4/7)", total_start_time, 0)
    from ultralytics import YOLO
    model_path = os.path.join(base_dir, "yolov8n.pt")
    model = YOLO(model_path)
    model_elapsed = time.time() - model_start_time
    show_progress(f"YOLOv8 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {int(model_elapsed)}ì´ˆ)", total_start_time, 100)
    
    # 5. ì„œë²„ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    data_start_time = time.time()
    show_progress("ì„œë²„ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (5/7)", total_start_time, 0)
    dataset = download_dataset_with_progress(data_start_time)
    data_elapsed = time.time() - data_start_time
    show_progress(f"ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {int(data_elapsed)}ì´ˆ)", total_start_time, 100)
    
   # 6. ë°ì´í„° ê²½ë¡œ í™•ì¸
    path_start_time = time.time()
    show_progress("ë°ì´í„° ê²½ë¡œ í™•ì¸ ì¤‘... (6/7)", total_start_time, 0)
    # dataset ê°ì²´ì˜ location ì†ì„±ì„ ì‚¬ìš©
    tutorial_dataset_dataset_dir = dataset.location
    data_yaml_path = os.path.join(tutorial_dataset_dataset_dir, "data.yaml")
    path_elapsed = time.time() - path_start_time
    show_progress(f"ë°ì´í„° ê²½ë¡œ í™•ì¸ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {int(path_elapsed)}ì´ˆ)", total_start_time, 100)
    
    # 7. í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • ë° ì‹¤í–‰
    train_start_time = time.time()
    show_progress("ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ ì¤‘... (7/7)", total_start_time, 0)
    
    batch_size = 16
    if device == "cuda" and gpu_info.get("available", False):
        # GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ì¡°ì •
        memory = gpu_info.get("memory_gb", [0])[0]
        if memory and memory < 6:
            batch_size = 8
            show_progress(f"GPU ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ ë°°ì¹˜ í¬ê¸° {batch_size}ë¡œ ì¡°ì •", total_start_time, 10)
    
    # ì—í­ ìˆ˜
    epochs = 2 if device == "cuda" else 1
    
    show_progress(f"ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ë””ë°”ì´ìŠ¤: {device}, ë°°ì¹˜ í¬ê¸°: {batch_size}, ì—í­: {epochs})", total_start_time, 20)
    show_progress("í•™ìŠµ ì¤‘... (YOLOv8 ì§„í–‰ ìƒí™©ì´ í‘œì‹œë©ë‹ˆë‹¤)", total_start_time, 30)
    show_progress("ì´ ì‘ì—…ì€ GPU ì‚¬ìš© ì‹œ ì•½ 10-30ë¶„, CPU ì‚¬ìš© ì‹œ 1-3ì‹œê°„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤", total_start_time, 40)
    
    try:
        # í•™ìŠµ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        epoch_start_time = time.time()
        last_progress_update = time.time()
        
        # í•™ìŠµ ì§„í–‰ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•  ë³€ìˆ˜ë“¤
        completed_epochs = 0
        total_epochs = epochs
        
        # í•™ìŠµ ì§„í–‰ë¥ ì„ ì£¼ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜
        def update_training_progress():
            nonlocal completed_epochs
            nonlocal last_progress_update
            
            while completed_epochs < total_epochs:
                time.sleep(5)  # 5ì´ˆë§ˆë‹¤ í™•ì¸
                
                # í˜„ì¬ ì‹œê°„ ê¸°ë¡
                current_time = time.time()
                
                # 10ì´ˆë§ˆë‹¤ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                if current_time - last_progress_update >= 10:
                    progress = (completed_epochs / total_epochs) * 100
                    elapsed = current_time - epoch_start_time
                    minutes, seconds = divmod(elapsed, 60)
                    
                    # ì”ì—¬ ì‹œê°„ ì¶”ì •
                    if completed_epochs > 0:
                        time_per_epoch = elapsed / completed_epochs
                        remaining_epochs = total_epochs - completed_epochs
                        remaining_time = time_per_epoch * remaining_epochs
                        rem_minutes, rem_seconds = divmod(remaining_time, 60)
                        
                        show_progress(
                            f"í•™ìŠµ ì¤‘: {completed_epochs}/{total_epochs} ì—í­ ì™„ë£Œ "
                            f"({int(minutes)}ë¶„ {int(seconds)}ì´ˆ ê²½ê³¼, ì•½ {int(rem_minutes)}ë¶„ {int(rem_seconds)}ì´ˆ ë‚¨ìŒ)", 
                            total_start_time, 
                            40 + (progress * 0.6)  # 40% ~ 100% ë²”ìœ„
                        )
                    else:
                        show_progress(
                            f"í•™ìŠµ ì¤‘: {completed_epochs}/{total_epochs} ì—í­ ì™„ë£Œ "
                            f"({int(minutes)}ë¶„ {int(seconds)}ì´ˆ ê²½ê³¼)", 
                            total_start_time, 
                            40 + (progress * 0.6)
                        )
                    
                    last_progress_update = current_time
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        progress_thread = threading.Thread(target=update_training_progress)
        progress_thread.daemon = True
        progress_thread.start()
        
        # í•™ìŠµ ì‹¤í–‰ (í´ë˜ìŠ¤ ì†ì„±ì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸)
        class ProgressCallback:
            def __init__(self):
                pass
            
            @staticmethod
            def on_train_epoch_end(trainer):
                nonlocal completed_epochs
                completed_epochs = trainer.epoch + 1  # ì—í­ì€ 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1
        
        # ì½œë°± ê°ì²´ ìƒì„±
        callbacks = [ProgressCallback()]

        
        # í•™ìŠµ ì‹¤í–‰
        model.train(
            data=data_yaml_path,
            epochs=epochs,
            batch=batch_size,
            imgsz=640,
            device=device,
            project=os.path.join(base_dir, "runs"),
            name="detect/train",  # í•˜ìœ„ í´ë” êµ¬ì¡° ì§€ì •
            exist_ok=True  # ê¸°ì¡´ í´ë”ê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
        )
    
        # ì§„í–‰ ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
        completed_epochs = total_epochs
        
        # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
        if progress_thread and progress_thread.is_alive():
            progress_thread.join(timeout=1)
        
        train_elapsed = time.time() - train_start_time
        min, sec = divmod(train_elapsed, 60)
        show_progress(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {int(min)}ë¶„ {int(sec)}ì´ˆ)", total_start_time, 100)
    except Exception as e:
        show_progress(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", total_start_time, 70)
        
        # ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ ì²˜ë¦¬
        if "CUDA out of memory" in str(e):
            show_progress("GPU ë©”ëª¨ë¦¬ ë¶€ì¡±. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.", total_start_time, 75)
            try:
                # ë°°ì¹˜ í¬ê¸° ì ˆë°˜ìœ¼ë¡œ ì¤„ì„
                reduced_batch = max(1, batch_size // 2)
                retry_start = time.time()
                show_progress(f"ì¤„ì–´ë“  ë°°ì¹˜ í¬ê¸°ë¡œ ì¬ì‹œë„ ì¤‘ (ë°°ì¹˜ í¬ê¸°: {reduced_batch})...", total_start_time, 80)
                
                # ì§„í–‰ ìƒí™©ì„ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œì‘
                completed_epochs = 0
                last_progress_update = time.time()
                
                # ì¬ì‹œë„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ìƒˆ ìŠ¤ë ˆë“œ
                retry_thread = threading.Thread(target=update_training_progress)
                retry_thread.daemon = True
                retry_thread.start()
                
                # ì¤„ì–´ë“  ë°°ì¹˜ í¬ê¸°ë¡œ í•™ìŠµ ì¬ì‹œë„
                model.train(
                    data=data_yaml_path,
                    epochs=epochs,
                    batch=reduced_batch,
                    imgsz=640,
                    device=device,
                    project=os.path.join(base_dir, "runs"),
                    name="detect/train",  # í•˜ìœ„ í´ë” êµ¬ì¡° ì§€ì •
                    exist_ok=True  # ê¸°ì¡´ í´ë”ê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
                )
                
                # ì§„í–‰ ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
                completed_epochs = total_epochs
                
                # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
                if retry_thread and retry_thread.is_alive():
                    retry_thread.join(timeout=1)
                
                retry_elapsed = time.time() - retry_start
                min, sec = divmod(retry_elapsed, 60)
                show_progress(f"ë°°ì¹˜ í¬ê¸° {reduced_batch}ë¡œ í•™ìŠµ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {int(min)}ë¶„ {int(sec)}ì´ˆ)", total_start_time, 100)
            except Exception as e2:
                show_progress(f"ì¬ì‹œë„ë„ ì‹¤íŒ¨: {e2}", total_start_time, 85)
                # CPUë¡œ ì „í™˜
                show_progress("CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...", total_start_time, 90)
                cpu_start = time.time()
                show_progress("CPUë¡œ í•™ìŠµ ì¤‘ (ì´ ì‘ì—…ì€ 1-3ì‹œê°„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)...", total_start_time, 93)
                
                # CPUë¡œ ì „í™˜í•˜ê³  ì—í­ ìˆ˜ ì¤„ì„
                completed_epochs = 0
                total_epochs = 50  # CPUì—ì„œëŠ” ì—í­ ìˆ˜ ì¤„ì„
                last_progress_update = time.time()
                
                # CPU í•™ìŠµ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ìƒˆ ìŠ¤ë ˆë“œ
                cpu_thread = threading.Thread(target=update_training_progress)
                cpu_thread.daemon = True
                cpu_thread.start()
                
                model.train(
                    data=data_yaml_path,
                    epochs=total_epochs,
                    batch=4,
                    imgsz=640,
                    device="cpu",
                    project=os.path.join(base_dir, "runs"),
                    name="detect/train",  # í•˜ìœ„ í´ë” êµ¬ì¡° ì§€ì •
                    exist_ok=True  # ê¸°ì¡´ í´ë”ê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
                )
                
                # ì§„í–‰ ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
                completed_epochs = total_epochs
                
                # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
                if cpu_thread and cpu_thread.is_alive():
                    cpu_thread.join(timeout=1)
                
                cpu_elapsed = time.time() - cpu_start
                hrs, remainder = divmod(cpu_elapsed, 3600)
                mins, secs = divmod(remainder, 60)
                show_progress(f"CPUë¡œ í•™ìŠµ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {int(hrs)}ì‹œê°„ {int(mins)}ë¶„ {int(secs)}ì´ˆ)", total_start_time, 100)
                
    # 8. í•™ìŠµ ê²°ê³¼ ì²˜ë¦¬ ì¤‘
    show_progress("í•™ìŠµ ê²°ê³¼ ì²˜ë¦¬ ì¤‘...", total_start_time, 100)
    
   # ê²°ê³¼ ì €ì¥ ê²½ë¡œë¥¼ Python í´ë” ë‚´ë¡œ ì„¤ì •
    results_dir = os.path.join(base_dir, "runs", "detect", "train")
    
    # 9. í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ ì‹œê°í™”
    results_image_path = os.path.join(results_dir, "results.png")
    visualize_result = visualize_training_results(results_image_path, total_start_time)

    # 10. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ì¶”ë¡  ì‹¤í–‰
    inference_result = None
    model_path = os.path.join(results_dir, "weights", "best.pt")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (ë¡œì»¬ ê²½ë¡œ)
    # ë°ì´í„°ì…‹ í´ë”ì—ì„œ test/images í´ë” ë‚´ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì‚¬ìš©
    test_image_path = None
    # dataset_dir = os.path.join(base_dir, "dataset")
    # tutorial_dataset_dir = os.path.join(dataset_dir, "tutorial_dataset")
    
    # # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë” ê²½ë¡œë“¤ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ ìœ„ì¹˜ ê²€ìƒ‰)
    # possible_test_folders = [
    #     os.path.join(tutorial_dataset_dir, "dataset", "test", "images"),
    #     os.path.join(tutorial_dataset_dir, "test", "images"),
    #     os.path.join(tutorial_dataset_dir, "dataset", "valid", "images"),  # ê²€ì¦ ì´ë¯¸ì§€ë„ ì‹œë„
    #     os.path.join(tutorial_dataset_dir, "valid", "images"),
    #     os.path.join(tutorial_dataset_dir, "dataset", "train", "images"),  # í•™ìŠµ ì´ë¯¸ì§€ë„ ì‹œë„
    #     os.path.join(tutorial_dataset_dir, "train", "images")
    # ]
    
    # # ì‚¬ìš© ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°
    # for folder in possible_test_folders:
    #     if os.path.exists(folder):
    #         image_files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp'))]
    #         if image_files:
    #             test_image_path = os.path.join(folder, image_files[0])
    #             show_progress(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë°œê²¬: {test_image_path}", total_start_time, 100)
    #             break
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ì¶”ë¡  ì‹¤í–‰
    if test_image_path and os.path.exists(test_image_path):
        inference_start_time = time.time()
        show_progress(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì¶”ë¡  ì¤‘... ({test_image_path})", total_start_time, 100)
        inference_result = run_inference(model_path, test_image_path, inference_start_time)
    else:
        show_progress("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¶”ë¡ ì„ ê±´ë„ˆëœë‹ˆë‹¤.", total_start_time, 100)
    
    # 11. í•™ìŠµ ì™„ë£Œ ì•Œë¦¼
    total_elapsed = time.time() - total_start_time
    hrs, remainder = divmod(total_elapsed, 3600)
    mins, secs = divmod(remainder, 60)
    
    show_progress(f"íŠœí† ë¦¬ì–¼ ëª¨ë“œ ì‹¤í–‰ ì™„ë£Œ! (ì´ ì†Œìš” ì‹œê°„: {int(hrs)}ì‹œê°„ {int(mins)}ë¶„ {int(secs)}ì´ˆ)", total_start_time, 100)
    show_progress(f"í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ: {model_path}", total_start_time, 100)

    # ìµœì‹  ê²°ê³¼ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
    results_dir = find_latest_results_dir()
    model_path = os.path.join(results_dir, "weights", "best.pt")
    
    show_progress(f"íŠœí† ë¦¬ì–¼ ëª¨ë“œ ì‹¤í–‰ ì™„ë£Œ! (ì´ ì†Œìš” ì‹œê°„: {int(hrs)}ì‹œê°„ {int(mins)}ë¶„ {int(secs)}ì´ˆ)", total_start_time, 100)
    show_progress(f"í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ: {model_path}", total_start_time, 100)
    
    # ê²°ê³¼ ì •ë³´
    result = {
        "success": True,
        "model_path": model_path,
        "results_path": results_image_path if visualize_result else None,
        "device_used": device,
        "gpu_info": gpu_info,
        "total_time_seconds": total_elapsed,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    # ì¶”ë¡  ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if inference_result:
        result["inference"] = {
            "image_path": inference_result["image_path"],
            "result_image": inference_result["result_image"],
            "detections_count": len(inference_result["detections"]),
            "detections": inference_result["detections"]
        }
    
    # JSONìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥ (C# í”„ë¡œê·¸ë¨ì—ì„œ íŒŒì‹±)
    print(f"RESULT_JSON:{json.dumps(result)}")
    return result

# ì¶”ë¡  ì „ìš© í•¨ìˆ˜
def infer_image(model_path, image_path, show=False):
    """ëª¨ë¸ì„ ì‚¬ìš©í•´ ê°œë³„ ì´ë¯¸ì§€ ì¶”ë¡  (ì™¸ë¶€ì—ì„œ í˜¸ì¶œìš©)"""
    start_time = time.time()
    show_progress(f"ì´ë¯¸ì§€ ì¶”ë¡  ìš”ì²­: {image_path}", start_time, 0)
    
    # ì¶”ë¡  ì‹¤í–‰
    result = run_inference(model_path, image_path, start_time, show=show)
    
    if result:
        print(f"INFERENCE_RESULT:{json.dumps(result)}")
        return result
    else:
        error_result = {
            "success": False,
            "error": "ì¶”ë¡  ì‹¤íŒ¨",
            "image_path": image_path,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        print(f"INFERENCE_RESULT:{json.dumps(error_result)}")
        return error_result

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ í™•ì¸
    if len(sys.argv) > 2 and sys.argv[1] == "infer":
        # ì¶”ë¡  ëª¨ë“œ: python script.py infer <ëª¨ë¸_ê²½ë¡œ> <ì´ë¯¸ì§€_ê²½ë¡œ>
        try:
            model_path = sys.argv[2]
            image_path = sys.argv[3]
            infer_image(model_path, image_path, show=True)
        except Exception as e:
            error_result = {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            print(f"INFERENCE_RESULT:{json.dumps(error_result)}")
    else:
        # ì¼ë°˜ ëª¨ë“œ: ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        try:
            main()
        except Exception as e:
            logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            error_result = {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            print(f"RESULT_JSON:{json.dumps(error_result)}")