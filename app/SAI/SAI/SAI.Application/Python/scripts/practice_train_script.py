#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
practice_train_script.py - AI ë¸”ë¡ ì½”ë”© íŠœí† ë¦¬ì–¼ ëª¨ë“œ êµ¬í˜„

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” AI ë¸”ë¡ ì½”ë”© íŠœí† ë¦¬ì–¼ ëª¨ë“œë¥¼ ìœ„í•œ ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
install_packages.pyì˜ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜, GPU í™•ì¸ ë“±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
import json
import time
import threading
import zipfile
import glob
import io
import re
import shutil
import torch

from datetime import datetime
# ë¡œê¹… ë ˆë²¨ ì„¤ì •
logging.getLogger().setLevel(logging.INFO)

print("[DEBUG] practice_train_script.py ì‹œì‘", flush=True)

try:
    # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    print(f"[DEBUG] base_dir ì„¤ì •ë¨: {base_dir}", flush=True)

    # í˜„ì¬ íŒŒì¼ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ scripts ë””ë ‰í† ë¦¬ ì–»ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    print(f"[DEBUG] current_dir: {current_dir}", flush=True)

    # scripts ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
        print(f"[DEBUG] sys.pathì— ì¶”ê°€ëœ ê²½ë¡œ: {current_dir}", flush=True)

    # install_packages ê°€ì ¸ì˜¤ê¸°
    print("[DEBUG] install_packages ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ì‹œë„", flush=True)
    try:
        import install_packages
        print("[DEBUG] install_packages ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ", flush=True)
    except Exception as e:
        print(f"[DEBUG] install_packages ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}", flush=True)
        raise

    # python-dotenv ê°€ì ¸ì˜¤ê¸°
    print("[DEBUG] python-dotenv ê°€ì ¸ì˜¤ê¸° ì‹œë„", flush=True)
    try:
        from dotenv import load_dotenv
        print("[DEBUG] python-dotenv ê°€ì ¸ì˜¤ê¸° ì„±ê³µ", flush=True)
    except Exception as e:
        print(f"[DEBUG] python-dotenv ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}", flush=True)
        raise
    
    # .env íŒŒì¼ ë¡œë“œ
    env_path = os.path.join(current_dir, '.env')
    print(f"[DEBUG] .env íŒŒì¼ ê²½ë¡œ: {env_path}", flush=True)
    
    if os.path.exists(env_path):
        print("[DEBUG] .env íŒŒì¼ ì¡´ì¬í•¨", flush=True)
        try:
            load_dotenv(env_path)
            print("[DEBUG] .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ", flush=True)
            api_url = os.getenv('API_SERVER_URL')
            print(f"[DEBUG] API_SERVER_URL: {api_url}", flush=True)
        except Exception as e:
            print(f"[DEBUG] .env íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}", flush=True)
            raise
    else:
        print("[DEBUG] .env íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ", flush=True)
        raise FileNotFoundError(".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # í‘œì¤€ ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
    print("[DEBUG] í‘œì¤€ ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ ì„¤ì • ì‹œë„", flush=True)
    print("[DEBUG] í‘œì¤€ ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ ì„¤ì • ìƒëµ", flush=True)

    # ë¡œê¹… ì„¤ì •
    print("[DEBUG] ë¡œê¹… ì„¤ì • ì‹œë„", flush=True)
    try:
        logging.basicConfig(
            level=logging.DEBUG,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout)
            ]
        )
        print("[DEBUG] ë¡œê¹… ì„¤ì • ì™„ë£Œ", flush=True)
    except Exception as e:
        print(f"[DEBUG] ë¡œê¹… ì„¤ì • ì‹¤íŒ¨: {str(e)}", flush=True)
        raise

    # install_packagesì˜ ì§„í–‰ ìƒí™© í‘œì‹œ í•¨ìˆ˜ ì‚¬ìš©
    print("[DEBUG] show_progress í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸° ì‹œë„", flush=True)
    show_progress = install_packages.show_progress
    print("[DEBUG] show_progress í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ", flush=True)

    # ë¡œê·¸ íƒœê·¸ ìë™í™” ë˜í¼ í•¨ìˆ˜ ì¶”ê°€

    def show_tagged_progress(tag, message, start_time=None, progress=None):
        """
        íƒœê·¸ë¥¼ ìë™ìœ¼ë¡œ ë¶™ì—¬ì„œ show_progressë¥¼ í˜¸ì¶œí•˜ëŠ” ë˜í¼ í•¨ìˆ˜
        tag: ë¬¸ìì—´(ì˜ˆ: 'INFO', 'ERROR', 'DATASET', 'TRAIN', 'INFER' ë“±)
        message: ì‹¤ì œ ë©”ì‹œì§€
        start_time, progress: ê¸°ì¡´ show_progressì™€ ë™ì¼
        """
        tagged_message = f"[{tag}] {message}"
        show_progress(tagged_message, start_time, progress)

    # ì‚¬ìš© ì˜ˆì‹œ:
    # show_tagged_progress('DATASET', 'ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...', start_time, 0)
    # show_tagged_progress('ERROR', f'ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}', start_time, 100)
    # show_tagged_progress('TRAIN', 'í•™ìŠµ ì‹œì‘', start_time, 10)

    # íŠœí† ë¦¬ì–¼ ìƒíƒœ ê´€ë¦¬ìš© ì „ì—­ ë³€ìˆ˜
    print("[DEBUG] practice_state ì´ˆê¸°í™” ì‹œë„", flush=True)
    practice_state = {
        "model": None,
        "model_path": None,
        "dataset_path": None,
        "data_yaml_path": None,
        "image_path": None,
        "result_image_path": None,
        "training_completed": False
    }
    print("[DEBUG] practice_state ì´ˆê¸°í™” ì™„ë£Œ", flush=True)

    print("[DEBUG] practice_train_script.py ì´ˆê¸°í™” ì™„ë£Œ", flush=True)

except Exception as e:
    logger.error(f"practice_train_script.py ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
    print(f"PROGRESS::ìŠ¤í¬ë¦½íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", flush=True)
    raise

# ================== 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë¸”ë¡ í•¨ìˆ˜ ==================
def install_packages_block(block_params=None):
    """íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜"""
    print("[DEBUG] install_packages_block í•¨ìˆ˜ ì§„ì…", flush=True)

    start_time = time.time()
    show_tagged_progress('TRAIN', 'í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤', start_time, 0)
    
    # íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìˆœì„œ ë³€ê²½ ë° ë²„ì „ ëª…ì‹œ (numpy 1.19.2 í˜¸í™˜)
    packages = [
        "numpy==1.19.2",
        "matplotlib==3.3.4",  # numpy 1.19.2ì™€ í˜¸í™˜
        "ultralytics==8.0.100",  # ë” ë‚®ì€ ë²„ì „ ì‚¬ìš©
        "opencv-python==4.6.0.66"  # ë” ë‚®ì€ ë²„ì „ ì‚¬ìš©
    ]
    
    try:
        result = install_packages.install_packages_with_progress(packages, start_time)
        print("[DEBUG] install_packages_with_progress ê²°ê³¼:", result, flush=True)
        
        pkg_elapsed = time.time() - start_time
        show_tagged_progress('TRAIN', f'í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ (ì†Œìš” ì‹œê°„: {int(pkg_elapsed)}ì´ˆ)', start_time, 100)
        
        return {
            "success": result.get("success", False),
            "installed_packages": result.get("installed_packages", []),
            "failed_packages": result.get("failed_packages", []),
            "elapsed_time": pkg_elapsed
        }
    except Exception as e:
        show_tagged_progress('ERROR', f'íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}', start_time, 100)
        return {
            "success": False,
            "error": str(e),
            "elapsed_time": time.time() - start_time
        }

# ================== 2. GPU í™•ì¸ ë° ëª¨ë¸ ë¡œë“œ ë¸”ë¡ í•¨ìˆ˜ ==================
def check_gpu_yolo_load_block(block_params=None):
    """GPU ìƒíƒœ í™•ì¸ ë° ëª¨ë¸ ë¡œë“œ ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜"""
    # 1. GPU í™•ì¸ í”„ë¡œê·¸ë ˆìŠ¤
    gpu_start_time = time.time()
    show_tagged_progress('TRAIN', 'GPU ì •ë³´ í™•ì¸ ì¤‘...', gpu_start_time, 0)
    gpu_info = install_packages.check_gpu(gpu_start_time)
    time.sleep(0.5)  # ì‹¤ì œ í™•ì¸ ì‹œê°„ ëŒ€ì²´(ì‹œë®¬ë ˆì´ì…˜)
    show_tagged_progress('TRAIN', 'GPU ì •ë³´ í™•ì¸ ì™„ë£Œ', gpu_start_time, 100)

    # 2. block_paramsì—ì„œ model_type ë°›ê¸° (ê¸°ë³¸ê°’: 'n')
    model_type = 'n'
    if block_params and 'model_type' in block_params:
        if block_params['model_type'] in ['n', 's', 'm', 'l']:
            model_type = block_params['model_type']

    # 3. ëª¨ë¸ ë¡œë“œ í”„ë¡œê·¸ë ˆìŠ¤ (ë³„ë„ start_time ì‚¬ìš©)
    model_load_time = time.time()
    show_tagged_progress('TRAIN', f'YOLOv8{model_type} ëª¨ë¸ ë¡œë“œ ì¤‘...', model_load_time, 0)
    try:
        from ultralytics import YOLO
        model_filename = f'yolov8{model_type}.pt'
        model_path = os.path.join(base_dir, model_filename)
        # ëª¨ë¸ ë¡œë”© ì§„í–‰ ì‹œë®¬ë ˆì´ì…˜
        for progress in [10, 30, 50, 70, 90]:
            show_tagged_progress('TRAIN', f'YOLOv8{model_type} ëª¨ë¸ ë¡œë“œ ì¤‘...', model_load_time, progress)
            time.sleep(0.2)
        model = YOLO(model_path)
        show_tagged_progress('TRAIN', f'YOLOv8{model_type} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!', model_load_time, 100)

        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
        practice_state["model"] = model
        practice_state["model_path"] = model_path

        return {
            "success": True,
            "gpu_info": gpu_info,
            "model_path": model_path,
            "elapsed_time": time.time() - gpu_start_time
        }
    except Exception as e:
        show_tagged_progress('ERROR', f'ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}', model_load_time, 100)
        return {
            "success": False,
            "error": str(e),
            "gpu_info": gpu_info
        }

# ================== 2-1. ì»¤ìŠ¤í…€ ëª¨ë¸ ë ˆì´ì–´ ì„¤ì • ë° ë¡œë“œ ë¸”ë¡ í•¨ìˆ˜ ==================
def load_model_with_layer_block(block_params=None):
    """
    loadModelWithLayer ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜
    ì‚¬ìš©ì íŒŒë¼ë¯¸í„°ë¡œ ì»¤ìŠ¤í…€ YAMLì„ ìƒì„±í•˜ê³  ëª¨ë¸ì„ ë¡œë“œ
    
    Args:
        block_params (dict): ë¸”ë¡ì—ì„œ ì „ë‹¬ë°›ì€ íŒŒë¼ë¯¸í„°
            - Conv: 64, 128, 256
            - C2f: 1, 2, 3  
            - Upsample_scale: 2.0, 3.0, 4.0
    """
    start_time = time.time()
    show_tagged_progress('TRAIN', 'ì»¤ìŠ¤í…€ ëª¨ë¸ ë ˆì´ì–´ ì„¤ì • ì‹œì‘...', start_time, 0)
    
    try:
        # 1. GPU ì •ë³´ í™•ì¸ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        show_tagged_progress('TRAIN', 'GPU ì •ë³´ í™•ì¸ ì¤‘...', start_time, 10)
        gpu_info = install_packages.check_gpu(start_time)
        
        # 2. ë¸”ë¡ íŒŒë¼ë¯¸í„° ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
        # C#ì—ì„œ ì „ë‹¬ë˜ëŠ” ëª¨ë¸ êµ¬ì¡° íŒŒë¼ë¯¸í„°ë“¤
        conv = block_params.get("Conv", 64) if block_params else 64
        c2f = block_params.get("C2f", 1) if block_params else 1
        upsample_scale = block_params.get("Upsample_scale", 2.0) if block_params else 2.0
        
        # ê¸°íƒ€ íŒŒë¼ë¯¸í„°ë“¤ (ìˆëŠ” ê²½ìš° ì²˜ë¦¬)
        if block_params:
            # ëª¨ë¸ ì´ë¦„ (ìˆëŠ” ê²½ìš°)
            if "model" in block_params:
                model_name = block_params["model"]
                show_tagged_progress('DEBUG', f'ëª¨ë¸ ì´ë¦„: {model_name}', start_time, 25)
            
            # ë¸”ë¡ íƒ€ì…ë“¤ (ìˆëŠ” ê²½ìš°)
            if "blockTypes" in block_params:
                block_types = block_params["blockTypes"] 
                show_tagged_progress('DEBUG', f'ë¸”ë¡ íƒ€ì…ë“¤: {block_types}', start_time, 25)
        
        # ìœ íš¨ ë²”ìœ„ í™•ì¸
        valid_conv = [64, 128, 256]
        valid_c2f = [1, 2, 3]
        valid_upsample = [2.0, 3.0, 4.0]
        
        if conv not in valid_conv:
            show_tagged_progress('WARN', f'Conv ê°’ {conv}ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 64 ì‚¬ìš©', start_time, 15)
            conv = 64
        if c2f not in valid_c2f:
            show_tagged_progress('WARN', f'C2f ê°’ {c2f}ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1 ì‚¬ìš©', start_time, 15)
            c2f = 1
        if upsample_scale not in valid_upsample:
            show_tagged_progress('WARN', f'Upsample_scale ê°’ {upsample_scale}ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 2.0 ì‚¬ìš©', start_time, 15)
            upsample_scale = 2.0
        
        show_tagged_progress('TRAIN', f'íŒŒë¼ë¯¸í„° í™•ì¸ ì™„ë£Œ: Conv={conv}, C2f={c2f}, Upsample={upsample_scale}', start_time, 20)
        
        # 3. ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸ (í´ë˜ìŠ¤ ìˆ˜ ìë™ ê°ì§€ìš©)
        dataset_path = practice_state.get("dataset_path")
        if not dataset_path:
            show_tagged_progress('WARN', 'ë°ì´í„°ì…‹ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ í´ë˜ìŠ¤ ìˆ˜(3) ì‚¬ìš©', start_time, 25)
            dataset_path = base_dir  # ì„ì‹œ ê²½ë¡œ
        
        # 4. ì»¤ìŠ¤í…€ YAML ìƒì„±
        show_tagged_progress('TRAIN', 'ì‚¬ìš©ì íŒŒë¼ë¯¸í„°ë¡œ ì»¤ìŠ¤í…€ YAML ìƒì„± ì¤‘...', start_time, 40)
        custom_yaml_path = generate_and_save_custom_yaml(
            conv_channels=conv,
            c2f_layers=c2f,
            upsample_scale=upsample_scale,
            dataset_path=dataset_path
        )
        
        # 5. ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ
        show_tagged_progress('TRAIN', 'ì»¤ìŠ¤í…€ YAMLë¡œ ëª¨ë¸ ë¡œë“œ ì¤‘...', start_time, 70)
        from ultralytics import YOLO
        
        # ì§„í–‰ ì‹œë®¬ë ˆì´ì…˜
        for progress in [75, 80, 85, 90, 95]:
            show_tagged_progress('TRAIN', f'ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì¤‘... ({progress}%)', start_time, progress)
            time.sleep(0.2)
        
        model = YOLO(custom_yaml_path)
        
        # 6. ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
        practice_state["model"] = model
        practice_state["model_path"] = custom_yaml_path
        practice_state["is_custom_model"] = True
        practice_state["custom_config"] = {
            "Conv": conv,
            "C2f": c2f, 
            "Upsample_scale": upsample_scale
        }
        
        show_tagged_progress('TRAIN', 'âœ… ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!', start_time, 100)
        print("custom.yaml ìƒì„± ì™„ë£Œ")  # ì‚¬ìš©ì í”¼ë“œë°±
        
        return {
            "success": True,
            "model_path": custom_yaml_path,
            "custom_config": {
                "Conv": conv,
                "C2f": c2f,
                "Upsample_scale": upsample_scale
            },
            "gpu_info": gpu_info,
            "elapsed_time": time.time() - start_time
        }
        
    except Exception as e:
        show_tagged_progress('ERROR', f'ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}', start_time, 100)
        return {
            "success": False,
            "error": str(e),
            "elapsed_time": time.time() - start_time
        }

def generate_and_save_custom_yaml(conv_channels=64, c2f_layers=1, upsample_scale=2.0, dataset_path=None):
    """
    ì»¤ìŠ¤í…€ YAML ìƒì„± ë° ì €ì¥ í•¨ìˆ˜
    
    Returns:
        str: ìƒì„±ëœ YAML íŒŒì¼ ê²½ë¡œ
    """
    import os
    
    # í´ë˜ìŠ¤ ìˆ˜ ìë™ ê°ì§€
    num_classes = 3  # ê¸°ë³¸ê°’
    if dataset_path:
        data_yaml_path = os.path.join(dataset_path, "data.yaml")
        if os.path.exists(data_yaml_path):
            try:
                import yaml
                with open(data_yaml_path, 'r', encoding='utf-8') as f:
                    data_config = yaml.safe_load(f)
                    num_classes = data_config.get('nc', 3)
            except Exception:
                pass
    
    # ì±„ë„ ìˆ˜ ê³„ì‚°
    ch1 = conv_channels
    ch2 = ch1 * 2
    ch3 = ch2 * 2  
    ch4 = ch3 * 2
    
    # YAML ë‚´ìš© ìƒì„±
    yaml_content = f"""# YOLOv8 Custom Model - Generated from Block Parameters
# Conv={conv_channels}, C2f={c2f_layers}, Upsample={upsample_scale}
nc: {num_classes}  # number of classes
depth_multiple: 0.33
width_multiple: 0.5

backbone:
  # [from, number, module, args]
  - [-1, 1, Conv, [{ch1}, 3, 2]]      # P1/2
  - [-1, 1, Conv, [{ch1}, 3, 2]]      # P2/4
  - [-1, {c2f_layers}, C2f, [{ch1}, True]]    # C2f layers = {c2f_layers}
  - [-1, 1, Conv, [{ch2}, 3, 2]]      # P3/8
  - [-1, {c2f_layers}, C2f, [{ch2}, True]]
  - [-1, 1, Conv, [{ch3}, 3, 2]]      # P4/16
  - [-1, {c2f_layers}, C2f, [{ch3}, True]]
  - [-1, 1, Conv, [{ch4}, 3, 2]]      # P5/32
  - [-1, {c2f_layers}, C2f, [{ch4}, True]]
  - [-1, 1, SPPF, [{ch4}, 5]]         # SPPF

head:
  - [-1, 1, nn.Upsample, [None, {upsample_scale}, 'nearest']]    # upsample = {upsample_scale}
  - [[-1, 6], 1, Concat, [1]]
  - [-1, {c2f_layers}, C2f, [{ch3}]]

  - [-1, 1, nn.Upsample, [None, {upsample_scale}, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]
  - [-1, {c2f_layers}, C2f, [{ch2}]]

  - [-1, 1, Conv, [{ch2}, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]
  - [-1, {c2f_layers}, C2f, [{ch3}]]

  - [-1, 1, Conv, [{ch3}, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]
  - [-1, {c2f_layers}, C2f, [{ch4}]]

  - [[15, 18, 21], 1, Detect, [nc]]

# ========== ìƒì„±ëœ ì„¤ì • ìš”ì•½ ==========
# Conv ì±„ë„: {conv_channels} â†’ ê³„ì¸µë³„ ì±„ë„ ìˆ˜: {ch1}-{ch2}-{ch3}-{ch4}
# C2f ë°˜ë³µ: {c2f_layers}íšŒ (ë†’ì„ìˆ˜ë¡ ë” ê¹Šì€ íŠ¹ì§• í•™ìŠµ)
# Upsample: {upsample_scale}ë°° (ì •ìˆ˜ë°°ë¡œ ì•ˆì •ì  ì—…ìƒ˜í”Œë§)
# í´ë˜ìŠ¤ ìˆ˜: {num_classes}ê°œ
"""
    
    # íŒŒì¼ ì €ì¥
    if dataset_path and os.path.exists(dataset_path):
        custom_yaml_path = os.path.join(dataset_path, "custom_model.yaml")
    else:
        custom_yaml_path = os.path.join(base_dir, "custom_model.yaml")
    
    with open(custom_yaml_path, 'w', encoding='utf-8') as f:
        f.write(yaml_content)
    
    print(f"ğŸ“Š ì»¤ìŠ¤í…€ ëª¨ë¸ ì„¤ì •: Conv={conv_channels}, C2f={c2f_layers}, Upsample={upsample_scale}, Classes={num_classes}")
    
    return custom_yaml_path

# ================== 3. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë¸”ë¡ í•¨ìˆ˜ ==================
def download_dataset_block(block_params=None):
    """ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜"""
    start_time = time.time()
    show_tagged_progress('DEBUG', 'ì„œë²„ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...', start_time)
    
    # API ì„œë²„ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    try:
        import requests
        from tqdm import tqdm
    except ImportError:
        show_tagged_progress('ERROR', 'í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...', start_time)
        install_packages.install_packages_with_progress(["requests", "tqdm"], start_time)
        import requests
        from tqdm import tqdm
    
    # ë°ì´í„°ì…‹ ì €ì¥ ê²½ë¡œ ë° ì™„ë£Œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    dataset_dir = os.path.join(base_dir, "dataset")
    os.makedirs(dataset_dir, exist_ok=True)
    done_file = os.path.join(dataset_dir, "practice_dataset_done.txt")

    # 1. ìºì‹±: ì™„ë£Œ íŒŒì¼ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if os.path.exists(done_file):
        show_tagged_progress('DATASET', 'ë°ì´í„°ì…‹ì´ ì´ë¯¸ ì¤€ë¹„ë˜ì–´ ìˆì–´ ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.', start_time, 100)
        time.sleep(1.5)  # ë©”ì‹œì§€ ì¸ì§€ ì‹œê°„ í™•ë³´
        extracted_dir = os.path.join(dataset_dir, "practice_dataset")
        data_yaml_path = find_yaml_file(dataset_dir, extracted_dir, start_time, mode="practice")
        practice_state["dataset_path"] = extracted_dir
        practice_state["data_yaml_path"] = data_yaml_path
        return {
            "success": True,
            "location": extracted_dir,
            "extracted_dir": extracted_dir,
            "data_yaml_path": data_yaml_path,
            "cached": True,
            "elapsed_time": time.time() - start_time
        }

    # 2. ê¸°ì¡´ practice ë°ì´í„°ì…‹ ê´€ë ¨ íŒŒì¼ë§Œ ì‚­ì œ
    practice_specific_files = ["practice_dataset", "practice_dataset.zip", "practice_dataset_done.txt"]
    for filename in practice_specific_files:
        file_path = os.path.join(dataset_dir, filename)
        try:
            if os.path.exists(file_path):
                if os.path.isfile(file_path) or os.path.islink(file_path):
                    os.unlink(file_path)
                    show_tagged_progress('DEBUG', f'ê¸°ì¡´ íŒŒì¼ ì‚­ì œ: {file_path}', start_time)
                elif os.path.isdir(file_path):
                    import shutil
                    shutil.rmtree(file_path)
                    show_tagged_progress('DEBUG', f'ê¸°ì¡´ í´ë” ì‚­ì œ: {file_path}', start_time)
        except Exception as e:
            show_tagged_progress('ERROR', f'ê¸°ì¡´ practice ë°ì´í„°ì…‹ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {e}', start_time)

    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„œë²„ ì£¼ì†Œ ê°€ì ¸ì˜¤ê¸°
    server_url = os.environ.get("API_SERVER_URL")
    if not server_url:
        show_tagged_progress('ERROR', 'API_SERVER_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.', start_time)
        
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
        practice_state["dataset_path"] = dataset_dir
        return {
            "success": True,
            "message": "í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ì‚¬ìš©",
            "location": dataset_dir
        }
    
    # ìŠ¬ë˜ì‹œë¡œ ëë‚˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
    if server_url.endswith('/'):
        server_url = server_url[:-1]
    
    # API ì—”ë“œí¬ì¸íŠ¸ URL êµ¬ì„±
    api_url = f"{server_url}/api/download/practice"
    show_tagged_progress('DEBUG', 'APIì—ì„œ ë‹¤ìš´ë¡œë“œ URL ìš”ì²­ ì¤‘...', start_time)
    
    zip_path = os.path.join(dataset_dir, "practice_dataset.zip")
    
    # API í˜¸ì¶œí•˜ì—¬ presigned URL ë°›ê¸°
    try:
        response = requests.get(api_url)
        if response.status_code == 200:
            data = response.json()
            download_url = data['result']
            show_tagged_progress('DEBUG', 'ë‹¤ìš´ë¡œë“œ URL íšë“ ì„±ê³µ', start_time)
        else:
            show_tagged_progress('ERROR', f'API í˜¸ì¶œ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status_code}', start_time)
            practice_state["dataset_path"] = dataset_dir
            return {
                "success": False,
                "error": f"API ì‘ë‹µ ì˜¤ë¥˜: {response.text}",
                "location": dataset_dir
            }
    except Exception as e:
        show_tagged_progress('ERROR', f'API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}', start_time)
        practice_state["dataset_path"] = dataset_dir
        return {
            "success": False,
            "error": str(e),
            "location": dataset_dir
        }
    
    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì§„í–‰ë¥  í‘œì‹œ)
    show_tagged_progress('DATASET', 'ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...', start_time, 0)
    try:
        response = requests.get(download_url, stream=True)
        total_size = int(response.headers.get('content-length', 0))
        
        # ë‹¤ìš´ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ ë° íŒŒì¼ ì €ì¥
        with open(zip_path, 'wb') as f:
            downloaded = 0
            for chunk in response.iter_content(chunk_size=1024*1024):  # 1MB ë‹¨ìœ„ë¡œ ì²­í¬ ë‹¤ìš´ë¡œë“œ
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    progress = min(0 + (downloaded / total_size * 50), 50) 
                    show_tagged_progress('DATASET', f'ë‹¤ìš´ë¡œë“œ ì¤‘: {downloaded//(1024*1024)}MB/{total_size//(1024*1024)}MB', start_time, progress)
        
        show_tagged_progress('DEBUG', 'ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ', start_time)
    except Exception as e:
        show_tagged_progress('ERROR', f'ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}', start_time)
        practice_state["dataset_path"] = dataset_dir
        return {
            "success": False,
            "error": str(e),
            "location": dataset_dir
        }
    
    # ZIP íŒŒì¼ ì••ì¶• í•´ì œ
    extracted_dir = dataset_dir  # ê¸°ë³¸ê°’ ì„¤ì •
    target_subdir = os.path.join(dataset_dir, "practice_dataset")

    if os.path.exists(zip_path):
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()
                total_files = len(file_list)
                show_tagged_progress('DATASET', f'ì••ì¶• íŒŒì¼ ë‚´ {total_files}ê°œ íŒŒì¼ ë°œê²¬', start_time, 70)

                # zip ë‚´ë¶€ì— practice_dataset/ í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
                has_top_dir = False
                if file_list and file_list[0].count('/') > 0:
                    top_dir = file_list[0].split('/')[0]
                    if top_dir == "practice_dataset":
                        has_top_dir = True

                if has_top_dir:
                    # ì´ë¯¸ í´ë”ê°€ ìˆìœ¼ë©´ ê¸°ì¡´ëŒ€ë¡œ ì••ì¶• í•´ì œ
                    potential_extracted_dir = os.path.join(dataset_dir, "practice_dataset")
                    for i, file in enumerate(file_list):
                        try:
                            zip_ref.extract(file, dataset_dir)
                            if i % 50 == 0 or i == total_files - 1:
                                extract_progress = 55 + (i / total_files) * 40
                                show_tagged_progress('DATASET', f'ì••ì¶• í•´ì œ ì¤‘: {i+1}/{total_files} íŒŒì¼', start_time, extract_progress)
                        except Exception as e:
                            show_tagged_progress('ERROR', f'íŒŒì¼ ì••ì¶• í•´ì œ ì‹¤íŒ¨ ({file}): {str(e)}', start_time)
                            continue
                    extracted_dir = potential_extracted_dir
                else:
                    # í´ë”ê°€ ì—†ìœ¼ë©´ dataset/practice_dataset/ì— ì••ì¶• í•´ì œ
                    os.makedirs(target_subdir, exist_ok=True)
                    for i, file in enumerate(file_list):
                        try:
                            # fileì´ í•˜ìœ„ í´ë” êµ¬ì¡°ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìƒëŒ€ ê²½ë¡œë¡œ ì¶”ì¶œ
                            dest_path = os.path.join(target_subdir, file)
                            dest_folder = os.path.dirname(dest_path)
                            os.makedirs(dest_folder, exist_ok=True)
                            
                            # ë””ë ‰í† ë¦¬ë§Œ ë‚˜íƒ€ë‚´ëŠ” í•­ëª©ì€ ê±´ë„ˆë›°ê¸° (ë§ˆì§€ë§‰ì´ '/'ë¡œ ëë‚˜ëŠ” ê²½ìš°)
                            if file.endswith('/'):
                                continue
                            
                            # ì²­í¬ ë‹¨ìœ„ë¡œ íŒŒì¼ ë³µì‚¬
                            with zip_ref.open(file) as source, open(dest_path, "wb") as target:
                                while True:
                                    chunk = source.read(8192)  # 8KB ì²­í¬ë¡œ ì½ê¸°
                                    if not chunk:
                                        break
                                    target.write(chunk)
                            
                            if i % 50 == 0 or i == total_files - 1:
                                extract_progress = 55 + (i / total_files) * 40
                                show_tagged_progress('DATASET', f'ì••ì¶• í•´ì œ ì¤‘: {i+1}/{total_files} íŒŒì¼', start_time, extract_progress)
                        except Exception as e:
                            show_tagged_progress('ERROR', f'íŒŒì¼ ì••ì¶• í•´ì œ ì‹¤íŒ¨ ({file}): {str(e)}', start_time)
                            continue
                    extracted_dir = target_subdir
                    show_tagged_progress('DEBUG', f'ì••ì¶•ì„ {target_subdir}ì— í•´ì œí•¨', start_time)
            show_tagged_progress('DEBUG', 'ì••ì¶• í•´ì œ ì™„ë£Œ', start_time, 100)
                
            # ì„ì‹œ ZIP íŒŒì¼ ì‚­ì œ (ì ì‹œ ê¸°ë‹¤ë¦° í›„ ì‹œë„)
            time.sleep(1)  # íŒŒì¼ í•¸ë“¤ì´ ëª¨ë‘ ë‹«í ì‹œê°„ì„ ì¤ë‹ˆë‹¤
            try:
                os.remove(zip_path)
                show_tagged_progress('DEBUG', 'ì„ì‹œ ZIP íŒŒì¼ ì‚­ì œ ì™„ë£Œ', start_time)
            except Exception as e:
                show_tagged_progress('DEBUG', f'ì„ì‹œ ZIP íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}', start_time)
        
        except Exception as e:
            show_tagged_progress('DEBUG', f'ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì˜¤ë¥˜: {e}', start_time)
    else:
        show_tagged_progress('ERROR', 'ë‹¤ìš´ë¡œë“œëœ ZIP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', start_time)                           
                
                
        
    # ë°ì´í„°ì…‹ ê²½ë¡œ ì €ì¥
    practice_state["dataset_path"] = extracted_dir

    # data.yaml íŒŒì¼ ì°¾ê¸°
    data_yaml_path = find_yaml_file(dataset_dir, extracted_dir, start_time, mode="practice")
    if data_yaml_path is None:
        show_tagged_progress('ERROR', 'data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.', start_time)
        data_yaml_path = os.path.join(extracted_dir, 'data.yaml')  # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •

    practice_state["data_yaml_path"] = data_yaml_path
    show_tagged_progress('DATASET', 'ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ', start_time, 100)

    # ì™„ë£Œ íŒŒì¼ ìƒì„±
    try:
        with open(done_file, "w") as f:
            f.write("done")
        show_tagged_progress('DEBUG', 'ë°ì´í„°ì…‹ ì™„ë£Œ íŒŒì¼ ìƒì„±', start_time, 100)
    except Exception as e:
        show_tagged_progress('ERROR', f'ì™„ë£Œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}', start_time)

    return {
            "success": True,
            "location": extracted_dir,
            "extracted_dir": extracted_dir,
            "data_yaml_path": data_yaml_path,
            "elapsed_time": time.time() - start_time
        }   

# data.yaml íŒŒì¼ ì°¾ê¸° ë„ìš°ë¯¸ í•¨ìˆ˜ ìˆ˜ì •
def find_yaml_file(dataset_dir, extracted_dir, start_time, mode="practice"):
    """
    ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ì—ì„œ data.yaml íŒŒì¼ ì°¾ê¸°
    
    Args:
        dataset_dir: ê¸°ë³¸ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        extracted_dir: ì••ì¶• í•´ì œëœ ë””ë ‰í† ë¦¬
        start_time: ì‹œì‘ ì‹œê°„ (ë¡œê¹…ìš©)
        mode: ê²€ìƒ‰ ëª¨ë“œ ('tutorial' ë˜ëŠ” 'practice')
    """
    show_tagged_progress('DEBUG', f'ë°ì´í„° ê²½ë¡œ í™•ì¸: {extracted_dir} (ëª¨ë“œ: {mode})', start_time)
    
    # ëª¨ë“œë³„ ë””ë ‰í† ë¦¬ ì„¤ì •
    target_dir = os.path.join(dataset_dir, f"{mode}_dataset")
    show_tagged_progress('DEBUG', f'íƒ€ê²Ÿ ë””ë ‰í† ë¦¬: {target_dir}', start_time)
    
    # 1. ì§ì ‘ ì§€ì •ëœ ê²½ë¡œì—ì„œ ì°¾ê¸°
    yaml_path = os.path.join(extracted_dir, "data.yaml")
    if os.path.exists(yaml_path):
        show_tagged_progress('DEBUG', f'ë°ì´í„° íŒŒì¼ í™•ì¸ë¨: {yaml_path}', start_time)
        return yaml_path
    
    # 2. ëª¨ë“œë³„ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
    yaml_path = os.path.join(target_dir, "data.yaml")
    if os.path.exists(yaml_path):
        show_tagged_progress('DEBUG', f'ëª¨ë“œë³„ ë””ë ‰í† ë¦¬ì—ì„œ ë°ì´í„° íŒŒì¼ í™•ì¸ë¨: {yaml_path}', start_time)
        return yaml_path
    
    # 3. ëª¨ë“œë³„ ë””ë ‰í† ë¦¬ì˜ í•˜ìœ„ í´ë”ë“¤ì—ì„œë§Œ data.yaml ì°¾ê¸°
    if os.path.exists(target_dir):
        for root, dirs, files in os.walk(target_dir):
            for file in files:
                if file == "data.yaml":
                    yaml_path = os.path.join(root, file)
                    show_tagged_progress('DEBUG', f'ëª¨ë“œë³„ í•˜ìœ„ í´ë”ì—ì„œ ë°ì´í„° íŒŒì¼ í™•ì¸ë¨: {yaml_path}', start_time)
                    return yaml_path
    
    # íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš°
    show_tagged_progress('ERROR', f'{mode}_datasetì—ì„œ data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤', start_time)
    return None

# ================== 4. ëª¨ë¸ í•™ìŠµ ë¸”ëŸ­ ==================
def train_model_block(block_params=None):
    """
    ëª¨ë¸ í•™ìŠµ ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        block_params (dict): ë¸”ë¡ì—ì„œ ì „ë‹¬ë°›ì€ íŒŒë¼ë¯¸í„°
            - epoch (int): ì‚¬ìš©ìê°€ ì§€ì •í•œ ì—í­ ìˆ˜
            - imgsz (int): ì‚¬ìš©ìê°€ ì§€ì •í•œ ì´ë¯¸ì§€ í¬ê¸°
            - accuracy (float): ì‹ ë¢°ë„ ì„ê³„ê°’ (ì¶”ë¡ ì—ì„œ ì‚¬ìš©)
            
    ì£¼ì˜: Conv, C2f, Upsample_scaleì€ load_model_with_layer_blockì—ì„œ ì²˜ë¦¬ë¨
    """
    start_time = time.time()
    show_tagged_progress('TRAIN', 'ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ ì¤‘...', start_time, 0)

    # í•™ìŠµ ê´€ë ¨ íŒŒë¼ë¯¸í„°ë§Œ ì¶”ì¶œ
    epochs = block_params.get("epochs") if block_params else None
    imgsz = block_params.get("image_size") if block_params else None
    
    # ì¶”ë¡ ì—ì„œ ì‚¬ìš©í•  íŒŒë¼ë¯¸í„° (í•™ìŠµì—ì„œëŠ” ì €ì¥ë§Œ)
    if block_params and "accuracy" in block_params:
        practice_state["inference_accuracy"] = block_params["accuracy"]    

    # ê¸°ì¡´ results.csv ì‚­ì œ
    results_csv = os.path.join(base_dir, "runs", "detect", "train", "results.csv")
    if os.path.exists(results_csv):
        os.remove(results_csv)
        show_tagged_progress('DEBUG', 'ê¸°ì¡´ results.csv íŒŒì¼ ì‚­ì œ ì™„ë£Œ', start_time, 18)

    # í•„ìš”í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    if not practice_state.get("model"):
        show_tagged_progress('ERROR', 'ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ ë¡œë“œ ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.', start_time, 10)
        return {
            "success": False,
            "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ"
        }
    
    if not practice_state.get("data_yaml_path"):
        show_tagged_progress('ERROR', 'ë°ì´í„°ì…‹ YAML íŒŒì¼ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ ì¤€ë¹„ ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.', start_time, 10)
        return {
            "success": False,
            "error": "ë°ì´í„°ì…‹ YAML íŒŒì¼ ì—†ìŒ"
        }
    
    # ì»¤ìŠ¤í…€ ëª¨ë¸ ì •ë³´ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
    if practice_state.get("is_custom_model") and practice_state.get("custom_config"):
        config = practice_state["custom_config"]
        show_tagged_progress('TRAIN', f'ì»¤ìŠ¤í…€ ëª¨ë¸ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ: Conv={config.get("Conv")}, C2f={config.get("C2f")}, Upsample={config.get("Upsample_scale")}', start_time, 15)
    
    # GPU ì •ë³´ í™•ì¸
    gpu_info = install_packages.check_gpu(start_time)
    device = "cuda" if gpu_info.get("available", False) else "cpu"
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •
    batch_size = 16
    if device == "cuda" and gpu_info.get("available", False):
        memory = gpu_info.get("memory_gb", [0])[0]
        if memory and memory < 6:
            batch_size = 8
            show_tagged_progress('TRAIN', f'GPU ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ ë°°ì¹˜ í¬ê¸° {batch_size}ë¡œ ì¡°ì •', start_time, 10)
    
    # ì—í­ ìˆ˜ ì„¤ì • - ì‚¬ìš©ì ì§€ì • ê°’ ë˜ëŠ” ê¸°ë³¸ê°’
    if epochs is None:
        # ê¸°ë³¸ ì—í­ ìˆ˜ ì„¤ì • (í´ë¼ì´ì–¸íŠ¸ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•œ ê²½ìš° ìš°ì„  ì‚¬ìš©)
        epochs = 1  # ê¸°ë³¸ê°’ì„ 1ë¡œ ë³€ê²½ (ë¡œì»¬ê³¼ ë™ì¼í•˜ê²Œ)
    else:
        # ì‚¬ìš©ì ì§€ì • ì—í­ ìˆ˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
        try:
            epochs = int(epochs)
            if epochs <= 0:
                show_tagged_progress('ERROR', f'ì—í­ ìˆ˜ëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.', start_time, 15)
                epochs = 1  # ê¸°ë³¸ê°’ì„ 1ë¡œ ë³€ê²½
        except ValueError:
            show_tagged_progress('ERROR', f'ìœ íš¨í•˜ì§€ ì•Šì€ ì—í­ ìˆ˜ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.', start_time, 15)
            epochs = 1  # ê¸°ë³¸ê°’ì„ 1ë¡œ ë³€ê²½
    
    # ì´ë¯¸ì§€ í¬ê¸° ì„¤ì • - ì‚¬ìš©ì ì§€ì • ê°’ ë˜ëŠ” ê¸°ë³¸ê°’
    if imgsz is None:
        # ê¸°ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
        imgsz = 640
    else:
        # ì‚¬ìš©ì ì§€ì • ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
        try:
            imgsz = int(imgsz)
            # ìœ íš¨í•œ ì´ë¯¸ì§€ í¬ê¸° ë²”ìœ„ í™•ì¸ (YOLO ê¶Œì¥ í¬ê¸°)
            valid_sizes = [512, 640, 960, 1024, 1280]
            if imgsz not in valid_sizes:
                # ê°€ì¥ ê°€ê¹Œìš´ ìœ íš¨ í¬ê¸° ì°¾ê¸°
                closest_size = min(valid_sizes, key=lambda x: abs(x - imgsz))
                show_tagged_progress('ERROR', f'ì´ë¯¸ì§€ í¬ê¸° {imgsz}ëŠ” ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê°€ì¥ ê°€ê¹Œìš´ ê¶Œì¥ í¬ê¸° {closest_size}ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.', start_time, 15)
                imgsz = closest_size
        except ValueError:
            show_tagged_progress('ERROR', f'ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í¬ê¸°ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ 640ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.', start_time, 15)
            imgsz = 640
    
    show_tagged_progress('TRAIN', f'ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ë””ë°”ì´ìŠ¤: {device}, ë°°ì¹˜ í¬ê¸°: {batch_size}, ì—í­: {epochs}, ì´ë¯¸ì§€ í¬ê¸°: {imgsz})', start_time, 20)
    
    try:
        # í•™ìŠµ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        epoch_start_time = time.time()
        last_progress_update = time.time()
        
        # í•™ìŠµ ì§„í–‰ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•  ë³€ìˆ˜ë“¤
        completed_epochs = 0
        total_epochs = epochs
        
        # í•™ìŠµ ì‹¤í–‰ (í´ë˜ìŠ¤ ì†ì„±ì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸)
        class ProgressCallback:
            def __init__(self):
                self.start_time = time.time()
            
            def on_train_epoch_end(self, trainer):
                nonlocal completed_epochs
                completed_epochs = trainer.epoch + 1
                progress = (completed_epochs / total_epochs) * 100
                elapsed = time.time() - self.start_time
                minutes, seconds = divmod(elapsed, 60)
                
                # ì”ì—¬ ì‹œê°„ ì¶”ì •
                if completed_epochs > 1:
                    time_per_epoch = elapsed / completed_epochs
                    remaining_epochs = total_epochs - completed_epochs
                    remaining_time = time_per_epoch * remaining_epochs
                    rem_minutes, rem_seconds = divmod(remaining_time, 60)
                    bar = make_progress_bar(progress)
                    print(f"PROGRESS:{progress:.1f}:[ì „ì²´ {progress:.1f}% | {int(minutes):02d}:{int(seconds):02d} ê²½ê³¼ | {int(rem_minutes):02d}:{int(rem_seconds):02d} ë‚¨ìŒ] [TRAIN] {bar} ({completed_epochs}/{total_epochs} ì—í­) í•™ìŠµ ì¤‘", flush=True)
                else:
                    bar = make_progress_bar(progress)
                    print(f"PROGRESS:{progress:.1f}:[ì „ì²´ {progress:.1f}% | {int(minutes):02d}:{int(seconds):02d} ê²½ê³¼] [TRAIN] {bar} ({completed_epochs}/{total_epochs} ì—í­) í•™ìŠµ ì¤‘", flush=True)
        
        # ì½œë°± ê°ì²´ ìƒì„±
        callbacks = [ProgressCallback()]
        
        # í•™ìŠµ ì‹¤í–‰
        model = practice_state["model"]
        data_yaml_path = practice_state["data_yaml_path"]
        
        # YOLOv8 í•™ìŠµ ì‹¤í–‰ - verbose=Trueë¡œ ì„¤ì •í•˜ì—¬ ë¡œê·¸ ì¶œë ¥ í™œì„±í™”
        show_tagged_progress('TRAIN', 'YOLO train() ë©”ì†Œë“œ í˜¸ì¶œ ì¤‘...', start_time, 30)
        results = model.train(
            data=data_yaml_path,
            epochs=epochs,
            batch=batch_size,
            imgsz=imgsz,
            device=device,
            project=os.path.join(base_dir, "runs"),
            name="detect/train",  # í•˜ìœ„ í´ë” êµ¬ì¡° ì§€ì •
            exist_ok=True,
            workers = 0,
        )
        
        show_tagged_progress('TRAIN', 'YOLO í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤', start_time, 90)
        
        # ê²°ê³¼ ê²½ë¡œ ì„¤ì •
        results_dir = find_latest_results_dir()
        model_path = os.path.join(results_dir, "weights", "best.pt")
        
        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
        practice_state["model_path"] = model_path
        practice_state["results_dir"] = results_dir
        practice_state["training_completed"] = True
        
        train_elapsed = time.time() - start_time
        minutes, seconds = divmod(train_elapsed, 60)
        show_tagged_progress('TRAIN', f'ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ)', start_time, 100)
        
        return {
            "success": True,
            "model_path": model_path,
            "results_dir": results_dir,
            "epochs": epochs,
            "imgsz": imgsz,
            "device": device,
            "elapsed_time": train_elapsed
        }
    except Exception as e:
        show_tagged_progress('ERROR', f'í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}', start_time, 70)
        
        # ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ ì²˜ë¦¬
        if "CUDA out of memory" in str(e):
            show_tagged_progress('ERROR', 'GPU ë©”ëª¨ë¦¬ ë¶€ì¡±. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.', start_time, 75)
            try:
                # ë°°ì¹˜ í¬ê¸° ì ˆë°˜ìœ¼ë¡œ ì¤„ì„
                reduced_batch = max(1, batch_size // 2)
                retry_start = time.time()
                show_tagged_progress('TRAIN', f'ì¤„ì–´ë“  ë°°ì¹˜ í¬ê¸°ë¡œ ì¬ì‹œë„ ì¤‘ (ë°°ì¹˜ í¬ê¸°: {reduced_batch})...', start_time, 80)
                
                # ì¬ì‹œë„
                model = practice_state["model"]
                results = model.train(
                    data=practice_state["data_yaml_path"],
                    epochs=epochs,
                    batch=reduced_batch,
                    imgsz=imgsz,  # ì‚¬ìš©ì ì§€ì • ì´ë¯¸ì§€ í¬ê¸° ìœ ì§€
                    device=device,
                    project=os.path.join(base_dir, "runs"),
                    name="detect/train",
                    exist_ok=True,
                    workers = 0,
                )
                
                # ê²°ê³¼ ê²½ë¡œ ì„¤ì •
                results_dir = find_latest_results_dir()
                model_path = os.path.join(results_dir, "weights", "best.pt")
                
                # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
                practice_state["model_path"] = model_path
                practice_state["results_dir"] = results_dir
                practice_state["training_completed"] = True
                
                retry_elapsed = time.time() - retry_start
                minutes, seconds = divmod(retry_elapsed, 60)
                show_tagged_progress('TRAIN', f'ë°°ì¹˜ í¬ê¸° {reduced_batch}ë¡œ í•™ìŠµ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ)', start_time, 100)
                
                return {
                    "success": True,
                    "model_path": model_path,
                    "results_dir": results_dir,
                    "epochs": epochs,
                    "imgsz": imgsz,
                    "device": device,
                    "elapsed_time": time.time() - start_time,
                    "note": "ë°°ì¹˜ í¬ê¸° ê°ì†Œë¡œ ì¬ì‹œë„ ì„±ê³µ"
                }
            except Exception as e2:
                show_tagged_progress('ERROR', f'ì¬ì‹œë„ë„ ì‹¤íŒ¨: {e2}', start_time, 85)
                # CPUë¡œ ì „í™˜
                show_tagged_progress('TRAIN', 'CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...', start_time, 90)
                
                try:
                    # CPUë¡œ ì „í™˜í•˜ê³  ì—í­ ìˆ˜ ì¤„ì„
                    cpu_epochs = min(2, epochs)  # ì›ë˜ ì—í­ë³´ë‹¤ í¬ì§€ ì•Šê²Œ
                    model = practice_state["model"]
                    
                    results = model.train(
                        data=practice_state["data_yaml_path"],
                        epochs=cpu_epochs,
                        batch=4,
                        imgsz=imgsz,  # ì‚¬ìš©ì ì§€ì • ì´ë¯¸ì§€ í¬ê¸° ìœ ì§€
                        device="cpu",
                        project=os.path.join(base_dir, "runs"),
                        name="detect/train",
                        exist_ok=True,
                        workers = 0,
                    )
                    
                    # ê²°ê³¼ ê²½ë¡œ ì„¤ì •
                    results_dir = find_latest_results_dir()
                    model_path = os.path.join(results_dir, "weights", "best.pt")
                    
                    # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
                    practice_state["model_path"] = model_path
                    practice_state["results_dir"] = results_dir
                    practice_state["training_completed"] = True
                    
                    cpu_elapsed = time.time() - start_time
                    minutes, seconds = divmod(cpu_elapsed, 60)
                    show_tagged_progress('TRAIN', f'CPUë¡œ í•™ìŠµ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ)', start_time, 100)
                    
                    return {
                        "success": True,
                        "model_path": model_path,
                        "results_dir": results_dir,
                        "epochs": cpu_epochs,
                        "imgsz": imgsz,
                        "device": "cpu",
                        "elapsed_time": cpu_elapsed,
                        "note": "CPU ëª¨ë“œë¡œ ì „í™˜í•˜ì—¬ ì™„ë£Œ"
                    }
                except Exception as e3:
                    show_tagged_progress('ERROR', f'CPU ëª¨ë“œë„ ì‹¤íŒ¨: {e3}', start_time, 95)
                    return {
                        "success": False,
                        "error": str(e3),
                        "original_error": str(e)
                    }
        
        return {
            "success": False,
            "error": str(e)
        }

# ìµœì‹  ê²°ê³¼ ë””ë ‰í† ë¦¬ ì°¾ê¸° ë„ìš°ë¯¸ í•¨ìˆ˜
def find_latest_results_dir():
    """ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ results ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
    base_runs_dir = os.path.join(base_dir, "runs", "detect")
    
    if not os.path.exists(base_runs_dir):
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(base_runs_dir, exist_ok=True)
        return os.path.join(base_dir, "runs", "detect", "train")
    
    # 'train'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  í´ë” ì°¾ê¸°
    train_dirs = [d for d in os.listdir(base_runs_dir) if d.startswith('train')]
    if not train_dirs:
        return os.path.join(base_dir, "runs", "detect", "train")
    
    # ìˆ«ì ì ‘ë¯¸ì‚¬ê°€ ìˆëŠ” ê²½ìš° ê°€ì¥ í° ìˆ«ì ì°¾ê¸°
    latest_dir = "train"
    max_num = 0
    for d in train_dirs:
        # train, train1, train2, ... í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ
        match = re.match(r'train(\d*)', d)
        if match:
            num_str = match.group(1)
            num = int(num_str) if num_str else 0
            if num > max_num:
                max_num = num
                latest_dir = d
    
    return os.path.join(base_dir, "runs", "detect", latest_dir)

# ================== 5. ê²°ê³¼ ê·¸ë˜í”„ ì‹œê°í™” ë¸”ë¡ í•¨ìˆ˜ ==================
def visualize_training_results_block(block_params=None):
    """í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ ì‹œê°í™” ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜"""
    start_time = time.time()
    show_tagged_progress('TRAIN', 'í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì¤‘...', start_time, 0)
    
    # í•™ìŠµì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if not practice_state.get("training_completed"):
        show_tagged_progress('ERROR', 'í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.', start_time, 10)
        return {
            "success": False,
            "error": "í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•ŠìŒ"
        }
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
    results_dir = practice_state.get("results_dir")
    if not results_dir or not os.path.exists(results_dir):
        results_dir = find_latest_results_dir()
        practice_state["results_dir"] = results_dir
    
    # ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
    results_path = os.path.join(results_dir, "results.png")
    
    try:
        # ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(results_path):
            show_tagged_progress('ERROR', f'ê²°ê³¼ ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_path}', start_time, 50)
            
            # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
            alternative_paths = [
                os.path.join(results_dir, "results.png"),
                os.path.join(results_dir, "confusion_matrix.png"),
                os.path.join(results_dir, "val_batch0_pred.jpg")
            ]
            
            for alt_path in alternative_paths:
                if os.path.exists(alt_path):
                    results_path = alt_path
                    show_tagged_progress('DATASET', f'ëŒ€ì²´ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {results_path}', start_time, 60)
                    break
        
        # ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
        if os.path.exists(results_path):
            show_tagged_progress('TRAIN', f'í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ í™•ì¸: {results_path}', start_time, 80)
            try:
                # ì´ë¯¸ì§€ í‘œì‹œ (IPython í™˜ê²½ì—ì„œë§Œ ì‘ë™)
                from IPython.display import Image, display
                display(Image(filename=results_path))
                show_tagged_progress('TRAIN', 'ê²°ê³¼ ê·¸ë˜í”„ í‘œì‹œ ì™„ë£Œ', start_time, 100)
            except ImportError:
                # ì¼ë°˜ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ ê²½ë¡œë§Œ ë°˜í™˜
                show_tagged_progress('TRAIN', 'IPython í™˜ê²½ì´ ì•„ë‹ˆë¯€ë¡œ ê²°ê³¼ íŒŒì¼ ê²½ë¡œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.', start_time, 90)
            
            # ê²°ê³¼ ê²½ë¡œ ì €ì¥
            practice_state["results_image_path"] = results_path
            
            return {
                "success": True,
                "results_path": results_path,
                "elapsed_time": time.time() - start_time
            }
        else:
            show_tagged_progress('ERROR', 'ê²°ê³¼ ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', start_time, 100)
            return {
                "success": False,
                "error": "ê²°ê³¼ ê·¸ë˜í”„ íŒŒì¼ ì—†ìŒ",
                "elapsed_time": time.time() - start_time
            }
    except Exception as e:
        show_tagged_progress('ERROR', f'ê²°ê³¼ ì‹œê°í™” ì˜¤ë¥˜: {e}', start_time, 100)
        return {
            "success": False,
            "error": str(e),
            "elapsed_time": time.time() - start_time
        }

# 6. ì‚¬ìš©ì ì´ë¯¸ì§€ ê²½ë¡œ ë°›ëŠ” ë¸”ëŸ­
# ì´ë¯¸ì§€ ê²½ë¡œë¥¼ inference.py íŒŒì¼ë¡œ ë˜ì ¸ì¤€ë‹¤
def set_image_path_block(image_path=None, block_params=None):
    """
    ì¶”ë¡ ìš© ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        image_path (str, optional): ì‚¬ìš©ìê°€ ì§€ì •í•œ ì´ë¯¸ì§€ ê²½ë¡œ. 
                                   Noneì´ë©´ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸° ì‹œë„
    """
    start_time = time.time()
    show_tagged_progress('DATASET', 'ì¶”ë¡ ìš© ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • ì¤‘...', start_time, 0)
    
    if block_params and image_path is None:
        image_path = block_params.get("imgPath") or block_params.get("image_path")
    
    # ì‚¬ìš©ìê°€ ì§€ì •í•œ ì´ë¯¸ì§€ ê²½ë¡œê°€ ìˆëŠ”ì§€ í™•ì¸
    if image_path:
        # ì´ë¯¸ì§€ íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if os.path.exists(image_path):
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ì í™•ì¸
            if image_path.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                # ê²½ë¡œ ì €ì¥
                practice_state["image_path"] = image_path
                show_tagged_progress('DATASET', f'ì‚¬ìš©ì ì§€ì • ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • ì™„ë£Œ: {image_path}', start_time, 100)
                return {
                    "success": True,
                    "image_path": image_path,
                    "source_type": "user_specified",
                    "elapsed_time": time.time() - start_time
                }
            else:
                show_tagged_progress('ERROR', f'ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤: {image_path}', start_time, 50)
                return {
                    "success": False,
                    "error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹",
                    "elapsed_time": time.time() - start_time
                }
        else:
            show_tagged_progress('ERROR', f'ì§€ì •í•œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}', start_time, 50)
            return {
                "success": False,
                "error": "ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ",
                "elapsed_time": time.time() - start_time
            }

# ================== 7. ëª¨ë¸ ì¶”ë¡  ë¸”ë¡ í•¨ìˆ˜ ==================
def run_inference_block(block_params=None):
    """ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ ë¸”ë¡ í•¨ìˆ˜ - inference.py í™œìš©"""
    start_time = time.time()
    show_tagged_progress('INFER', 'ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ ì¤‘...', start_time, 0)
    
    # í•„ìš”í•œ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
    model_path = practice_state.get("model_path")
    if not model_path:
        # í•™ìŠµëœ ëª¨ë¸ì´ ì—†ë‹¤ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
        model_path = os.path.join(base_dir, "yolov8n.pt")
        show_tagged_progress('TRAIN', f'í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {model_path}', start_time, 10)
    
    image_path = practice_state.get("image_path")
    if not image_path:
        show_tagged_progress('ERROR', 'í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.', start_time, 10)
        return {
            "success": False,
            "error": "í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ì—†ìŒ"
        }
    
    # inference.py íŒŒì¼ ê²½ë¡œ í™•ì¸
    inference_script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "inference.py")
    if not os.path.exists(inference_script_path):
        show_tagged_progress('ERROR', f'inference.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {inference_script_path}', start_time, 20)
        return {
            "success": False,
            "error": "inference.py íŒŒì¼ ì—†ìŒ"
        }
    
    # ì¶”ë¡  ì‹¤í–‰ (inference.py í˜¸ì¶œ)
    try:
        show_tagged_progress('INFER', 'inference.pyë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ì‹¤í–‰ ì¤‘...', start_time, 30)
        
        # subprocessë¥¼ ì‚¬ìš©í•˜ì—¬ inference.py ì‹¤í–‰
        import subprocess
        
        # ëª…ë ¹ êµ¬ì„± - inference.pyì˜ ëª…ë ¹í–‰ ì¸ì í˜•ì‹ì— ë§ì¶¤
        cmd = [
            sys.executable,
            inference_script_path,
            "--model", model_path,
            "--image", image_path,
            "--conf", "0.25"
        ]
        
        show_tagged_progress('INFER', f'ì‹¤í–‰ ëª…ë ¹: {" ".join(cmd)}', start_time, 40)
        
        # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,
            bufsize=1,
            encoding='utf-8'
        )
        
        # ì¶œë ¥ ì²˜ë¦¬
        inference_result = None
        for line in iter(process.stdout.readline, ''):
            line = line.strip()
            print(line)  # ë¡œê·¸ í™•ì¸ìš©
            
            # ê²°ê³¼ JSON ì°¾ê¸°
            if line.startswith("INFERENCE_RESULT:"):
                result_json = line[len("INFERENCE_RESULT:"):]
                try:
                    inference_result = json.loads(result_json)
                    show_tagged_progress('INFER', 'ì¶”ë¡  ê²°ê³¼ JSON íŒŒì‹± ì„±ê³µ', start_time, 70)
                except json.JSONDecodeError:
                    show_tagged_progress('ERROR', f'ì¶”ë¡  ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨: {result_json}', start_time, 70)
            
            # ì§„í–‰ ìƒí™© ë©”ì‹œì§€ í™•ì¸
            elif line.startswith("[INFERENCE]"):
                progress_msg = line[len("[INFERENCE] "):]
                show_tagged_progress('INFER', f'ì¶”ë¡  ì§„í–‰ ì¤‘: {progress_msg}', start_time, 60)
        
        # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
        process.wait()
        
        # ê²°ê³¼ í™•ì¸
        if process.returncode != 0:
            stderr = process.stderr.read()
            show_tagged_progress('ERROR', f'inference.py ì‹¤í–‰ ì˜¤ë¥˜ (ë°˜í™˜ ì½”ë“œ: {process.returncode}): {stderr}', start_time, 80)
            return {
                "success": False,
                "error": f"inference.py ì‹¤í–‰ ì˜¤ë¥˜ (ë°˜í™˜ ì½”ë“œ: {process.returncode}): {stderr}",
                "elapsed_time": time.time() - start_time
            }
        
        # inference.pyê°€ ë°˜í™˜í•œ ê²°ê³¼ í™•ì¸
        if inference_result:
            # ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ ì €ì¥
            if "result_image" in inference_result:
                practice_state["result_image_path"] = inference_result["result_image"]
            
            show_tagged_progress('INFER', f'ì¶”ë¡  ì™„ë£Œ: {inference_result.get("success", False)}', start_time, 100)
            return {
                "success": inference_result.get("success", False),
                "result": inference_result,
                "elapsed_time": time.time() - start_time
            }
        else:
            show_tagged_progress('ERROR', 'inference.pyì—ì„œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.', start_time, 100)
            return {
                "success": False,
                "error": "inference.pyì—ì„œ ê²°ê³¼ê°€ ì—†ìŒ",
                "elapsed_time": time.time() - start_time
            }
    except Exception as e:
        show_tagged_progress('ERROR', f'ì¶”ë¡  ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}', start_time, 100)
        return {
            "success": False,
            "error": str(e),
            "elapsed_time": time.time() - start_time
        }

# ==================8. ê²°ê³¼ ì‹œê°í™” ë¸”ë¡ í•¨ìˆ˜ - inference.py ê²°ê³¼ í™œìš© ===================
def visualize_results_block(block_params=None):
    """ì¶”ë¡  ê²°ê³¼ ì‹œê°í™” ë¸”ë¡ ì‹¤í–‰ í•¨ìˆ˜"""
    start_time = time.time()
    show_tagged_progress('INFER', 'ì¶”ë¡  ê²°ê³¼ ì‹œê°í™” ì¤‘...', start_time, 0)
    
    # ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
    result_image_path = practice_state.get("result_image_path")
    if not result_image_path:
        show_tagged_progress('ERROR', 'ì¶”ë¡  ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ ì¶”ë¡  ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.', start_time, 10)
        return {
            "success": False,
            "error": "ì¶”ë¡  ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ ì—†ìŒ"
        }
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(result_image_path):
        show_tagged_progress('ERROR', f'ê²°ê³¼ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result_image_path}', start_time, 20)
        return {
            "success": False,
            "error": "ê²°ê³¼ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ"
        }
    
    # ë³„ë„ì˜ ì‹œê°í™” ì €ì¥ ì—†ì´, ê²½ë¡œë§Œ ë°˜í™˜
    show_tagged_progress('INFER', f'ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ ë°˜í™˜: {result_image_path}', start_time, 100)
    return {
        "success": True,
        "result_image_path": result_image_path,
        "elapsed_time": time.time() - start_time
    }

# =================== ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ========================
def main(block_params=None):
    """AI ë¸”ë¡ ì½”ë”© íŠœí† ë¦¬ì–¼ ëª¨ë“œ ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜"""
    total_start_time = time.time()
    current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    show_tagged_progress('TRAIN', f'AI ë¸”ë¡ ì½”ë”© íŠœí† ë¦¬ì–¼ ëª¨ë“œ ì‹¤í–‰ ì‹œì‘ - {current_date}', total_start_time, 0)
    
    # ì „ì²´ ë¸”ë¡ ìˆœì°¨ ì‹¤í–‰
    blocks = [
        ("íŒ¨í‚¤ì§€ ì„¤ì¹˜", install_packages_block),
        ("GPU í™•ì¸ ë° ëª¨ë¸ ë¡œë“œ", check_gpu_yolo_load_block),
        ("ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ", download_dataset_block),
        ("ëª¨ë¸ í•™ìŠµ", train_model_block),
        ("í•™ìŠµ ê²°ê³¼ ì‹œê°í™”", visualize_training_results_block),
        ("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •", set_image_path_block),
        ("ëª¨ë¸ ì¶”ë¡ ", run_inference_block),
        ("ì¶”ë¡  ê²°ê³¼ ì‹œê°í™”", visualize_results_block)
    ]
    
    results = {}
    success = True
    
    for i, (block_name, block_func) in enumerate(blocks):
        show_tagged_progress('TRAIN', f'ë¸”ë¡ ì‹¤í–‰ ì¤‘: {block_name} ({i+1}/{len(blocks)})', total_start_time, i * (100 / len(blocks)))
        try:
            result = block_func(block_params)
            results[block_name] = result
            
            if not result.get("success", False):
                success = False
                show_tagged_progress('ERROR', f'ë¸”ë¡ ì‹¤í–‰ ì‹¤íŒ¨: {block_name} - {result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")}', total_start_time, (i+1) * (100 / len(blocks)))
                break
            
            show_tagged_progress('TRAIN', f'ë¸”ë¡ ì‹¤í–‰ ì™„ë£Œ: {block_name}', total_start_time, (i+1) * (100 / len(blocks)))
        except Exception as e:
            success = False
            results[block_name] = {"success": False, "error": str(e)}
            show_tagged_progress('ERROR', f'ë¸”ë¡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {block_name} - {e}', total_start_time, (i+1) * (100 / len(blocks)))
            break
    
    # íŠœí† ë¦¬ì–¼ ì™„ë£Œ ë³´ê³ 
    total_elapsed = time.time() - total_start_time
    minutes, seconds = divmod(total_elapsed, 60)
    
    if success:
        show_tagged_progress('TRAIN', 'âœ… íŠœí† ë¦¬ì–¼ ëª¨ë“œ ì‹¤í–‰ ì™„ë£Œ! (ì´ ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ)', total_start_time, 100)
    else:
        show_tagged_progress('ERROR', f'âŒ íŠœí† ë¦¬ì–¼ ëª¨ë“œ ì‹¤í–‰ ì¤‘ë‹¨ (ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ)', total_start_time, 100)
    
    # ê²°ê³¼ ì •ë³´
    result = {
        "success": success,
        "blocks_results": results,
        "total_time_seconds": total_elapsed,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    # JSONìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥ (C# í”„ë¡œê·¸ë¨ì—ì„œ íŒŒì‹±)
    print(f"RESULT_JSON:{json.dumps(result, ensure_ascii=False)}")
    return result

#================ ì¶”ë¡ íƒ­ì—ì„œ ì¶”ë¡ í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤ ==================

# ì¶”ë¡  ì „ìš© í•¨ìˆ˜ (ì™¸ë¶€ì—ì„œ í˜¸ì¶œìš©)
def infer_image(model_path, image_path, show=False):
    """ëª¨ë¸ì„ ì‚¬ìš©í•´ ê°œë³„ ì´ë¯¸ì§€ ì¶”ë¡  (ì™¸ë¶€ì—ì„œ í˜¸ì¶œìš©) - inference.py í™œìš©"""
    start_time = time.time()
    show_tagged_progress('INFER', f'ì´ë¯¸ì§€ ì¶”ë¡  ìš”ì²­: {image_path}', start_time, 0)
    
    # inference.py íŒŒì¼ ê²½ë¡œ í™•ì¸
    inference_script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "inference.py")
    if not os.path.exists(inference_script_path):
        error_result = {
            "success": False,
            "error": f"inference.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {inference_script_path}",
            "image_path": image_path,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        print(f"INFERENCE_RESULT:{json.dumps(error_result, ensure_ascii=False)}")
        return error_result
    
    # inference.py ì‹¤í–‰
    try:
        import subprocess
        
        # ëª…ë ¹ êµ¬ì„±
        cmd = [
            sys.executable,
            inference_script_path,
            "--model", model_path,
            "--image", image_path,
            "--conf", "0.25"
        ]
        
        # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,
            bufsize=1,
            encoding='utf-8'
        )
        
        # ì¶œë ¥ ì²˜ë¦¬
        inference_result = None
        for line in iter(process.stdout.readline, ''):
            line = line.strip()
            print(line)  # ë¡œê·¸ í™•ì¸ìš©
            
            # ê²°ê³¼ JSON ì°¾ê¸°
            if line.startswith("INFERENCE_RESULT:"):
                result_json = line[len("INFERENCE_RESULT:"):]
                try:
                    inference_result = json.loads(result_json)
                    break
                except json.JSONDecodeError:
                    pass
        
        if inference_result:
            print(f"INFERENCE_RESULT:{json.dumps(inference_result, ensure_ascii=False)}")
            return inference_result
        else:
            error_result = {
                "success": False,
                "error": "inference.pyì—ì„œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "image_path": image_path,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            print(f"INFERENCE_RESULT:{json.dumps(error_result, ensure_ascii=False)}")
            return error_result
    except Exception as e:
        error_result = {
            "success": False,
            "error": str(e),
            "image_path": image_path,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        print(f"INFERENCE_RESULT:{json.dumps(error_result, ensure_ascii=False)}")
        return error_result

# =========== í”„ë¡œê·¸ë ˆìŠ¤ ë°” ê´€ë ¨ í•¨ìˆ˜ì…ë‹ˆë‹¤ ============= #
# í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë¬¸ìì—´ í•¨ìˆ˜
def make_progress_bar(progress, bar_length=20):
    filled_length = int(round(bar_length * progress / 100))
    bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
    return f"|{bar}| {progress:5.1f}%"

# ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ í¬ë§· í•¨ìˆ˜
def format_status(total_progress, elapsed, remain, tag, block_progress, bar, detail):
    return (f"[ì „ì²´ {total_progress:4.1f}% | {elapsed} ê²½ê³¼ | {remain} ë‚¨ìŒ] "
            f"[{tag}] {bar} {detail}")

# ë‚¨ì€ì‹œê°„ í¬ë§· í•¨ìˆ˜
def format_time(seconds):
    minutes, sec = divmod(int(seconds), 60)
    return f"{minutes:02d}:{sec:02d}"

# ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ + progress ë¡œê·¸ì¶œë ¥
def print_train_progress(epoch, total_epochs, total_progress, start_time, tag="TRAIN"):
    block_progress = (epoch / total_epochs) * 100
    bar = make_progress_bar(block_progress)
    elapsed = format_time(time.time() - start_time)
    # ë‚¨ì€ ì‹œê°„ ì˜ˆì¸¡
    if epoch > 1:
        avg_time = (time.time() - start_time) / epoch
        remain_sec = avg_time * (total_epochs - epoch)
    else:
        remain_sec = 0
    remain = format_time(remain_sec)
    detail = f"({epoch}/{total_epochs} ì—í­) í•™ìŠµ ì¤‘"
    print(f"PROGRESS:{block_progress:.1f}:[{tag}] {bar} {block_progress:.1f}% ({epoch}/{total_epochs} ì—í­) í•™ìŠµ ì¤‘ | ì „ì²´ {total_progress:.1f}% | ê²½ê³¼ {elapsed} | ë‚¨ìŒ {remain}", flush=True)


# progressbarë§Œ ì±„ìš°ëŠ” í•¨ìˆ˜
def print_block_progress(block_progress, message):
    # C#ì—ì„œ progressbarë§Œ ì±„ìš°ê³ , í…ìŠ¤íŠ¸ëŠ” ê°„ë‹¨í•˜ê²Œ
    print(f"PROGRESS:{block_progress:.1f}:{message}", flush=True)

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ í™•ì¸
    if len(sys.argv) > 2 and sys.argv[1] == "infer":
        # ì¶”ë¡  ëª¨ë“œ: python practice_train_script.py infer <ëª¨ë¸_ê²½ë¡œ> <ì´ë¯¸ì§€_ê²½ë¡œ>
        try:
            model_path = sys.argv[2]
            image_path = sys.argv[3]
            infer_image(model_path, image_path, show=True)
        except Exception as e:
            error_result = {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            print(f"INFERENCE_RESULT:{json.dumps(error_result, ensure_ascii=False)}")
    else:
        # ì¼ë°˜ ëª¨ë“œ: ì „ì²´ íŠœí† ë¦¬ì–¼ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        try:
            main()
        except Exception as e:
            logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            print(f"PROGRESS::í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", flush=True)
            error_result = {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            print(f"INFERENCE_RESULT:{json.dumps(error_result, ensure_ascii=False)}")
